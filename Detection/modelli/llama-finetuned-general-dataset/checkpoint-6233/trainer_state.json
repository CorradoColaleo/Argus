{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 6233,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001604492579221821,
      "grad_norm": 0.8839031457901001,
      "learning_rate": 0.00019971121450344939,
      "loss": 2.5229,
      "step": 10
    },
    {
      "epoch": 0.003208985158443642,
      "grad_norm": 0.552656888961792,
      "learning_rate": 0.00019939034172950426,
      "loss": 2.0814,
      "step": 20
    },
    {
      "epoch": 0.0048134777376654635,
      "grad_norm": 0.5598686337471008,
      "learning_rate": 0.00019906946895555913,
      "loss": 1.9176,
      "step": 30
    },
    {
      "epoch": 0.006417970316887284,
      "grad_norm": 0.5003688335418701,
      "learning_rate": 0.00019874859618161398,
      "loss": 2.1266,
      "step": 40
    },
    {
      "epoch": 0.008022462896109106,
      "grad_norm": 0.8043829798698425,
      "learning_rate": 0.00019842772340766885,
      "loss": 1.8958,
      "step": 50
    },
    {
      "epoch": 0.009626955475330927,
      "grad_norm": 0.6552237272262573,
      "learning_rate": 0.00019810685063372373,
      "loss": 1.861,
      "step": 60
    },
    {
      "epoch": 0.011231448054552748,
      "grad_norm": 0.5110681653022766,
      "learning_rate": 0.00019778597785977863,
      "loss": 1.8927,
      "step": 70
    },
    {
      "epoch": 0.012835940633774568,
      "grad_norm": 0.44909006357192993,
      "learning_rate": 0.00019746510508583348,
      "loss": 1.9883,
      "step": 80
    },
    {
      "epoch": 0.01444043321299639,
      "grad_norm": 0.4929358959197998,
      "learning_rate": 0.00019714423231188835,
      "loss": 1.7655,
      "step": 90
    },
    {
      "epoch": 0.016044925792218213,
      "grad_norm": 0.49080681800842285,
      "learning_rate": 0.00019682335953794322,
      "loss": 1.5639,
      "step": 100
    },
    {
      "epoch": 0.01764941837144003,
      "grad_norm": 0.5878735184669495,
      "learning_rate": 0.0001965024867639981,
      "loss": 1.7838,
      "step": 110
    },
    {
      "epoch": 0.019253910950661854,
      "grad_norm": 0.5352867841720581,
      "learning_rate": 0.00019618161399005294,
      "loss": 1.6937,
      "step": 120
    },
    {
      "epoch": 0.020858403529883673,
      "grad_norm": 0.6050840616226196,
      "learning_rate": 0.00019586074121610782,
      "loss": 1.8675,
      "step": 130
    },
    {
      "epoch": 0.022462896109105495,
      "grad_norm": 0.7767930626869202,
      "learning_rate": 0.0001955398684421627,
      "loss": 1.8401,
      "step": 140
    },
    {
      "epoch": 0.024067388688327317,
      "grad_norm": 0.5656359195709229,
      "learning_rate": 0.00019521899566821757,
      "loss": 1.7228,
      "step": 150
    },
    {
      "epoch": 0.025671881267549136,
      "grad_norm": 0.7401095032691956,
      "learning_rate": 0.00019489812289427244,
      "loss": 1.8926,
      "step": 160
    },
    {
      "epoch": 0.02727637384677096,
      "grad_norm": 0.6197347044944763,
      "learning_rate": 0.0001945772501203273,
      "loss": 1.8156,
      "step": 170
    },
    {
      "epoch": 0.02888086642599278,
      "grad_norm": 0.7293017506599426,
      "learning_rate": 0.0001942563773463822,
      "loss": 1.6635,
      "step": 180
    },
    {
      "epoch": 0.0304853590052146,
      "grad_norm": 1.0078816413879395,
      "learning_rate": 0.00019393550457243703,
      "loss": 1.5505,
      "step": 190
    },
    {
      "epoch": 0.032089851584436425,
      "grad_norm": 0.725098729133606,
      "learning_rate": 0.0001936146317984919,
      "loss": 1.8527,
      "step": 200
    },
    {
      "epoch": 0.03369434416365824,
      "grad_norm": 0.573114275932312,
      "learning_rate": 0.00019329375902454678,
      "loss": 1.7171,
      "step": 210
    },
    {
      "epoch": 0.03529883674288006,
      "grad_norm": 0.5792983770370483,
      "learning_rate": 0.00019297288625060163,
      "loss": 1.7582,
      "step": 220
    },
    {
      "epoch": 0.036903329322101885,
      "grad_norm": 0.624858558177948,
      "learning_rate": 0.0001926520134766565,
      "loss": 1.7336,
      "step": 230
    },
    {
      "epoch": 0.03850782190132371,
      "grad_norm": 0.6812928915023804,
      "learning_rate": 0.00019233114070271138,
      "loss": 1.7343,
      "step": 240
    },
    {
      "epoch": 0.04011231448054553,
      "grad_norm": 0.5076891779899597,
      "learning_rate": 0.00019201026792876625,
      "loss": 1.8648,
      "step": 250
    },
    {
      "epoch": 0.041716807059767345,
      "grad_norm": 0.812057614326477,
      "learning_rate": 0.00019168939515482112,
      "loss": 1.7501,
      "step": 260
    },
    {
      "epoch": 0.04332129963898917,
      "grad_norm": 0.7240645289421082,
      "learning_rate": 0.000191368522380876,
      "loss": 1.8057,
      "step": 270
    },
    {
      "epoch": 0.04492579221821099,
      "grad_norm": 0.5552562475204468,
      "learning_rate": 0.00019104764960693087,
      "loss": 1.8181,
      "step": 280
    },
    {
      "epoch": 0.04653028479743281,
      "grad_norm": 0.5464973449707031,
      "learning_rate": 0.00019072677683298572,
      "loss": 1.6237,
      "step": 290
    },
    {
      "epoch": 0.048134777376654635,
      "grad_norm": 0.49023765325546265,
      "learning_rate": 0.0001904059040590406,
      "loss": 1.7109,
      "step": 300
    },
    {
      "epoch": 0.04973926995587646,
      "grad_norm": 0.47794824838638306,
      "learning_rate": 0.00019008503128509547,
      "loss": 1.9982,
      "step": 310
    },
    {
      "epoch": 0.05134376253509827,
      "grad_norm": 0.48744460940361023,
      "learning_rate": 0.00018976415851115034,
      "loss": 1.7214,
      "step": 320
    },
    {
      "epoch": 0.052948255114320095,
      "grad_norm": 0.6043136715888977,
      "learning_rate": 0.00018944328573720521,
      "loss": 1.8644,
      "step": 330
    },
    {
      "epoch": 0.05455274769354192,
      "grad_norm": 0.5961896777153015,
      "learning_rate": 0.0001891224129632601,
      "loss": 1.8081,
      "step": 340
    },
    {
      "epoch": 0.05615724027276374,
      "grad_norm": 0.7421380281448364,
      "learning_rate": 0.00018880154018931496,
      "loss": 1.8089,
      "step": 350
    },
    {
      "epoch": 0.05776173285198556,
      "grad_norm": 0.7412399053573608,
      "learning_rate": 0.0001884806674153698,
      "loss": 1.6232,
      "step": 360
    },
    {
      "epoch": 0.059366225431207384,
      "grad_norm": 0.42665690183639526,
      "learning_rate": 0.00018815979464142468,
      "loss": 1.591,
      "step": 370
    },
    {
      "epoch": 0.0609707180104292,
      "grad_norm": 0.5670799612998962,
      "learning_rate": 0.00018783892186747956,
      "loss": 1.6977,
      "step": 380
    },
    {
      "epoch": 0.06257521058965103,
      "grad_norm": 0.6879962682723999,
      "learning_rate": 0.00018751804909353443,
      "loss": 1.775,
      "step": 390
    },
    {
      "epoch": 0.06417970316887285,
      "grad_norm": 0.5174053311347961,
      "learning_rate": 0.00018719717631958928,
      "loss": 1.6413,
      "step": 400
    },
    {
      "epoch": 0.06578419574809466,
      "grad_norm": 0.8301041722297668,
      "learning_rate": 0.00018687630354564415,
      "loss": 1.7396,
      "step": 410
    },
    {
      "epoch": 0.06738868832731648,
      "grad_norm": 0.6957445740699768,
      "learning_rate": 0.00018655543077169902,
      "loss": 1.7453,
      "step": 420
    },
    {
      "epoch": 0.0689931809065383,
      "grad_norm": 0.7472084164619446,
      "learning_rate": 0.0001862345579977539,
      "loss": 1.7135,
      "step": 430
    },
    {
      "epoch": 0.07059767348576013,
      "grad_norm": 0.5928587317466736,
      "learning_rate": 0.00018591368522380877,
      "loss": 1.4931,
      "step": 440
    },
    {
      "epoch": 0.07220216606498195,
      "grad_norm": 0.5596650242805481,
      "learning_rate": 0.00018559281244986365,
      "loss": 1.7735,
      "step": 450
    },
    {
      "epoch": 0.07380665864420377,
      "grad_norm": 0.5148088932037354,
      "learning_rate": 0.00018527193967591852,
      "loss": 1.7041,
      "step": 460
    },
    {
      "epoch": 0.0754111512234256,
      "grad_norm": 0.6777979135513306,
      "learning_rate": 0.00018495106690197337,
      "loss": 1.7087,
      "step": 470
    },
    {
      "epoch": 0.07701564380264742,
      "grad_norm": 0.5305657386779785,
      "learning_rate": 0.00018463019412802824,
      "loss": 1.4303,
      "step": 480
    },
    {
      "epoch": 0.07862013638186924,
      "grad_norm": 0.6925113201141357,
      "learning_rate": 0.00018430932135408311,
      "loss": 1.5368,
      "step": 490
    },
    {
      "epoch": 0.08022462896109106,
      "grad_norm": 0.7627392411231995,
      "learning_rate": 0.00018398844858013796,
      "loss": 1.6855,
      "step": 500
    },
    {
      "epoch": 0.08182912154031288,
      "grad_norm": 0.5606973767280579,
      "learning_rate": 0.00018366757580619286,
      "loss": 1.5445,
      "step": 510
    },
    {
      "epoch": 0.08343361411953469,
      "grad_norm": 0.7089872360229492,
      "learning_rate": 0.00018334670303224774,
      "loss": 1.7293,
      "step": 520
    },
    {
      "epoch": 0.08503810669875651,
      "grad_norm": 0.7811445593833923,
      "learning_rate": 0.0001830258302583026,
      "loss": 2.0119,
      "step": 530
    },
    {
      "epoch": 0.08664259927797834,
      "grad_norm": 0.4932338297367096,
      "learning_rate": 0.00018270495748435746,
      "loss": 1.7124,
      "step": 540
    },
    {
      "epoch": 0.08824709185720016,
      "grad_norm": 0.6280215978622437,
      "learning_rate": 0.00018238408471041233,
      "loss": 1.7816,
      "step": 550
    },
    {
      "epoch": 0.08985158443642198,
      "grad_norm": 0.49824514985084534,
      "learning_rate": 0.0001820632119364672,
      "loss": 1.8624,
      "step": 560
    },
    {
      "epoch": 0.0914560770156438,
      "grad_norm": 0.6941878199577332,
      "learning_rate": 0.00018174233916252208,
      "loss": 1.6904,
      "step": 570
    },
    {
      "epoch": 0.09306056959486562,
      "grad_norm": 0.7598250508308411,
      "learning_rate": 0.00018142146638857692,
      "loss": 1.6373,
      "step": 580
    },
    {
      "epoch": 0.09466506217408745,
      "grad_norm": 0.597557544708252,
      "learning_rate": 0.0001811005936146318,
      "loss": 1.7432,
      "step": 590
    },
    {
      "epoch": 0.09626955475330927,
      "grad_norm": 0.538303554058075,
      "learning_rate": 0.00018077972084068667,
      "loss": 1.7205,
      "step": 600
    },
    {
      "epoch": 0.09787404733253109,
      "grad_norm": 0.6846320033073425,
      "learning_rate": 0.00018045884806674155,
      "loss": 1.5717,
      "step": 610
    },
    {
      "epoch": 0.09947853991175291,
      "grad_norm": 0.7559964656829834,
      "learning_rate": 0.00018013797529279642,
      "loss": 1.5575,
      "step": 620
    },
    {
      "epoch": 0.10108303249097472,
      "grad_norm": 0.569990873336792,
      "learning_rate": 0.0001798171025188513,
      "loss": 1.6782,
      "step": 630
    },
    {
      "epoch": 0.10268752507019654,
      "grad_norm": 0.49274545907974243,
      "learning_rate": 0.00017949622974490617,
      "loss": 1.6661,
      "step": 640
    },
    {
      "epoch": 0.10429201764941837,
      "grad_norm": 0.791480541229248,
      "learning_rate": 0.00017917535697096101,
      "loss": 1.827,
      "step": 650
    },
    {
      "epoch": 0.10589651022864019,
      "grad_norm": 0.41648176312446594,
      "learning_rate": 0.0001788544841970159,
      "loss": 1.5756,
      "step": 660
    },
    {
      "epoch": 0.10750100280786201,
      "grad_norm": 0.7300043702125549,
      "learning_rate": 0.00017853361142307076,
      "loss": 1.7467,
      "step": 670
    },
    {
      "epoch": 0.10910549538708383,
      "grad_norm": 0.5319542288780212,
      "learning_rate": 0.0001782127386491256,
      "loss": 1.5766,
      "step": 680
    },
    {
      "epoch": 0.11070998796630566,
      "grad_norm": 0.4881877899169922,
      "learning_rate": 0.00017789186587518048,
      "loss": 1.6,
      "step": 690
    },
    {
      "epoch": 0.11231448054552748,
      "grad_norm": 0.8143187761306763,
      "learning_rate": 0.00017757099310123538,
      "loss": 1.8529,
      "step": 700
    },
    {
      "epoch": 0.1139189731247493,
      "grad_norm": 0.5314635634422302,
      "learning_rate": 0.00017725012032729026,
      "loss": 1.6586,
      "step": 710
    },
    {
      "epoch": 0.11552346570397112,
      "grad_norm": 0.6389960050582886,
      "learning_rate": 0.0001769292475533451,
      "loss": 1.7919,
      "step": 720
    },
    {
      "epoch": 0.11712795828319295,
      "grad_norm": 0.35823914408683777,
      "learning_rate": 0.00017660837477939998,
      "loss": 1.6836,
      "step": 730
    },
    {
      "epoch": 0.11873245086241477,
      "grad_norm": 0.5345970988273621,
      "learning_rate": 0.00017628750200545485,
      "loss": 1.6539,
      "step": 740
    },
    {
      "epoch": 0.12033694344163658,
      "grad_norm": 0.5727744102478027,
      "learning_rate": 0.0001759666292315097,
      "loss": 1.8354,
      "step": 750
    },
    {
      "epoch": 0.1219414360208584,
      "grad_norm": 0.5985836386680603,
      "learning_rate": 0.00017564575645756457,
      "loss": 1.6409,
      "step": 760
    },
    {
      "epoch": 0.12354592860008022,
      "grad_norm": 0.6133374571800232,
      "learning_rate": 0.00017532488368361945,
      "loss": 1.7506,
      "step": 770
    },
    {
      "epoch": 0.12515042117930206,
      "grad_norm": 0.4361981451511383,
      "learning_rate": 0.00017500401090967432,
      "loss": 1.9171,
      "step": 780
    },
    {
      "epoch": 0.12675491375852388,
      "grad_norm": 0.5325725674629211,
      "learning_rate": 0.0001746831381357292,
      "loss": 1.522,
      "step": 790
    },
    {
      "epoch": 0.1283594063377457,
      "grad_norm": 0.8345532417297363,
      "learning_rate": 0.00017436226536178407,
      "loss": 1.636,
      "step": 800
    },
    {
      "epoch": 0.1299638989169675,
      "grad_norm": 0.4875023365020752,
      "learning_rate": 0.00017404139258783894,
      "loss": 1.688,
      "step": 810
    },
    {
      "epoch": 0.13156839149618932,
      "grad_norm": 0.5051756501197815,
      "learning_rate": 0.0001737205198138938,
      "loss": 1.8586,
      "step": 820
    },
    {
      "epoch": 0.13317288407541114,
      "grad_norm": 0.5369932651519775,
      "learning_rate": 0.00017339964703994866,
      "loss": 1.6651,
      "step": 830
    },
    {
      "epoch": 0.13477737665463296,
      "grad_norm": 0.49759620428085327,
      "learning_rate": 0.00017307877426600354,
      "loss": 1.7412,
      "step": 840
    },
    {
      "epoch": 0.13638186923385479,
      "grad_norm": 0.41419872641563416,
      "learning_rate": 0.0001727579014920584,
      "loss": 1.535,
      "step": 850
    },
    {
      "epoch": 0.1379863618130766,
      "grad_norm": 0.45619550347328186,
      "learning_rate": 0.00017243702871811326,
      "loss": 1.7621,
      "step": 860
    },
    {
      "epoch": 0.13959085439229843,
      "grad_norm": 0.5468608736991882,
      "learning_rate": 0.00017211615594416813,
      "loss": 1.718,
      "step": 870
    },
    {
      "epoch": 0.14119534697152025,
      "grad_norm": 0.4654265344142914,
      "learning_rate": 0.00017179528317022303,
      "loss": 1.7663,
      "step": 880
    },
    {
      "epoch": 0.14279983955074207,
      "grad_norm": 0.5164316296577454,
      "learning_rate": 0.00017147441039627788,
      "loss": 1.6884,
      "step": 890
    },
    {
      "epoch": 0.1444043321299639,
      "grad_norm": 0.5143462419509888,
      "learning_rate": 0.00017115353762233275,
      "loss": 1.7174,
      "step": 900
    },
    {
      "epoch": 0.14600882470918572,
      "grad_norm": 0.7177920341491699,
      "learning_rate": 0.00017083266484838763,
      "loss": 1.6602,
      "step": 910
    },
    {
      "epoch": 0.14761331728840754,
      "grad_norm": 0.5272179841995239,
      "learning_rate": 0.0001705117920744425,
      "loss": 1.6954,
      "step": 920
    },
    {
      "epoch": 0.14921780986762936,
      "grad_norm": 0.7139653563499451,
      "learning_rate": 0.00017019091930049735,
      "loss": 1.6123,
      "step": 930
    },
    {
      "epoch": 0.1508223024468512,
      "grad_norm": 0.5485222339630127,
      "learning_rate": 0.00016987004652655222,
      "loss": 1.5548,
      "step": 940
    },
    {
      "epoch": 0.152426795026073,
      "grad_norm": 0.5027976036071777,
      "learning_rate": 0.0001695491737526071,
      "loss": 1.6123,
      "step": 950
    },
    {
      "epoch": 0.15403128760529483,
      "grad_norm": 0.8214656114578247,
      "learning_rate": 0.00016922830097866197,
      "loss": 1.7626,
      "step": 960
    },
    {
      "epoch": 0.15563578018451665,
      "grad_norm": 0.6398909687995911,
      "learning_rate": 0.00016890742820471684,
      "loss": 1.6428,
      "step": 970
    },
    {
      "epoch": 0.15724027276373848,
      "grad_norm": 0.4576755166053772,
      "learning_rate": 0.00016858655543077172,
      "loss": 1.5989,
      "step": 980
    },
    {
      "epoch": 0.1588447653429603,
      "grad_norm": 0.6657295227050781,
      "learning_rate": 0.0001682656826568266,
      "loss": 1.7357,
      "step": 990
    },
    {
      "epoch": 0.16044925792218212,
      "grad_norm": 0.6667534708976746,
      "learning_rate": 0.00016794480988288144,
      "loss": 1.7089,
      "step": 1000
    },
    {
      "epoch": 0.16205375050140394,
      "grad_norm": 0.6404911875724792,
      "learning_rate": 0.0001676239371089363,
      "loss": 1.9399,
      "step": 1010
    },
    {
      "epoch": 0.16365824308062576,
      "grad_norm": 0.5592930316925049,
      "learning_rate": 0.00016730306433499119,
      "loss": 1.6919,
      "step": 1020
    },
    {
      "epoch": 0.16526273565984756,
      "grad_norm": 0.6600384712219238,
      "learning_rate": 0.00016698219156104606,
      "loss": 1.7681,
      "step": 1030
    },
    {
      "epoch": 0.16686722823906938,
      "grad_norm": 0.42462167143821716,
      "learning_rate": 0.0001666613187871009,
      "loss": 1.7066,
      "step": 1040
    },
    {
      "epoch": 0.1684717208182912,
      "grad_norm": 0.8487841486930847,
      "learning_rate": 0.00016634044601315578,
      "loss": 1.8163,
      "step": 1050
    },
    {
      "epoch": 0.17007621339751303,
      "grad_norm": 0.45600637793540955,
      "learning_rate": 0.00016601957323921068,
      "loss": 1.687,
      "step": 1060
    },
    {
      "epoch": 0.17168070597673485,
      "grad_norm": 0.9732251763343811,
      "learning_rate": 0.00016569870046526553,
      "loss": 1.5643,
      "step": 1070
    },
    {
      "epoch": 0.17328519855595667,
      "grad_norm": 0.547324001789093,
      "learning_rate": 0.0001653778276913204,
      "loss": 1.6994,
      "step": 1080
    },
    {
      "epoch": 0.1748896911351785,
      "grad_norm": 0.7256927490234375,
      "learning_rate": 0.00016505695491737528,
      "loss": 1.795,
      "step": 1090
    },
    {
      "epoch": 0.17649418371440032,
      "grad_norm": 0.678226113319397,
      "learning_rate": 0.00016473608214343015,
      "loss": 1.6218,
      "step": 1100
    },
    {
      "epoch": 0.17809867629362214,
      "grad_norm": 0.49651530385017395,
      "learning_rate": 0.000164415209369485,
      "loss": 1.7222,
      "step": 1110
    },
    {
      "epoch": 0.17970316887284396,
      "grad_norm": 0.7691271901130676,
      "learning_rate": 0.00016409433659553987,
      "loss": 1.743,
      "step": 1120
    },
    {
      "epoch": 0.18130766145206578,
      "grad_norm": 0.8083658814430237,
      "learning_rate": 0.00016377346382159474,
      "loss": 1.6212,
      "step": 1130
    },
    {
      "epoch": 0.1829121540312876,
      "grad_norm": 0.7711095213890076,
      "learning_rate": 0.00016345259104764962,
      "loss": 1.5598,
      "step": 1140
    },
    {
      "epoch": 0.18451664661050943,
      "grad_norm": 0.4657856523990631,
      "learning_rate": 0.0001631317182737045,
      "loss": 1.5161,
      "step": 1150
    },
    {
      "epoch": 0.18612113918973125,
      "grad_norm": 0.5403220057487488,
      "learning_rate": 0.00016281084549975937,
      "loss": 1.8617,
      "step": 1160
    },
    {
      "epoch": 0.18772563176895307,
      "grad_norm": 0.4951678216457367,
      "learning_rate": 0.00016248997272581424,
      "loss": 1.6284,
      "step": 1170
    },
    {
      "epoch": 0.1893301243481749,
      "grad_norm": 0.4611455202102661,
      "learning_rate": 0.00016216909995186909,
      "loss": 1.7059,
      "step": 1180
    },
    {
      "epoch": 0.19093461692739672,
      "grad_norm": 0.5941755771636963,
      "learning_rate": 0.00016184822717792396,
      "loss": 1.6088,
      "step": 1190
    },
    {
      "epoch": 0.19253910950661854,
      "grad_norm": 0.584954559803009,
      "learning_rate": 0.00016152735440397883,
      "loss": 1.7178,
      "step": 1200
    },
    {
      "epoch": 0.19414360208584036,
      "grad_norm": 0.844161331653595,
      "learning_rate": 0.00016120648163003368,
      "loss": 1.6702,
      "step": 1210
    },
    {
      "epoch": 0.19574809466506218,
      "grad_norm": 0.651853084564209,
      "learning_rate": 0.00016088560885608855,
      "loss": 1.4762,
      "step": 1220
    },
    {
      "epoch": 0.197352587244284,
      "grad_norm": 0.5194754600524902,
      "learning_rate": 0.00016056473608214343,
      "loss": 1.6847,
      "step": 1230
    },
    {
      "epoch": 0.19895707982350583,
      "grad_norm": 0.5768997073173523,
      "learning_rate": 0.00016024386330819833,
      "loss": 1.5762,
      "step": 1240
    },
    {
      "epoch": 0.20056157240272765,
      "grad_norm": 0.5141549706459045,
      "learning_rate": 0.00015992299053425318,
      "loss": 1.5215,
      "step": 1250
    },
    {
      "epoch": 0.20216606498194944,
      "grad_norm": 0.5235623717308044,
      "learning_rate": 0.00015960211776030805,
      "loss": 1.5816,
      "step": 1260
    },
    {
      "epoch": 0.20377055756117127,
      "grad_norm": 0.7151733636856079,
      "learning_rate": 0.00015928124498636292,
      "loss": 1.6613,
      "step": 1270
    },
    {
      "epoch": 0.2053750501403931,
      "grad_norm": 0.6097338199615479,
      "learning_rate": 0.00015896037221241777,
      "loss": 1.5935,
      "step": 1280
    },
    {
      "epoch": 0.2069795427196149,
      "grad_norm": 0.6944005489349365,
      "learning_rate": 0.00015863949943847264,
      "loss": 1.5212,
      "step": 1290
    },
    {
      "epoch": 0.20858403529883673,
      "grad_norm": 0.720195472240448,
      "learning_rate": 0.00015831862666452752,
      "loss": 1.6436,
      "step": 1300
    },
    {
      "epoch": 0.21018852787805856,
      "grad_norm": 0.6142628788948059,
      "learning_rate": 0.0001579977538905824,
      "loss": 1.6084,
      "step": 1310
    },
    {
      "epoch": 0.21179302045728038,
      "grad_norm": 0.6659501791000366,
      "learning_rate": 0.00015767688111663727,
      "loss": 1.6657,
      "step": 1320
    },
    {
      "epoch": 0.2133975130365022,
      "grad_norm": 0.6570605039596558,
      "learning_rate": 0.00015735600834269214,
      "loss": 1.8426,
      "step": 1330
    },
    {
      "epoch": 0.21500200561572402,
      "grad_norm": 0.3953973650932312,
      "learning_rate": 0.00015703513556874701,
      "loss": 1.4626,
      "step": 1340
    },
    {
      "epoch": 0.21660649819494585,
      "grad_norm": 0.46896639466285706,
      "learning_rate": 0.00015671426279480186,
      "loss": 1.4854,
      "step": 1350
    },
    {
      "epoch": 0.21821099077416767,
      "grad_norm": 0.526200532913208,
      "learning_rate": 0.00015639339002085673,
      "loss": 1.6159,
      "step": 1360
    },
    {
      "epoch": 0.2198154833533895,
      "grad_norm": 0.4691866636276245,
      "learning_rate": 0.0001560725172469116,
      "loss": 1.653,
      "step": 1370
    },
    {
      "epoch": 0.2214199759326113,
      "grad_norm": 0.4344838559627533,
      "learning_rate": 0.00015575164447296648,
      "loss": 1.6893,
      "step": 1380
    },
    {
      "epoch": 0.22302446851183313,
      "grad_norm": 0.6522979736328125,
      "learning_rate": 0.00015543077169902133,
      "loss": 1.6526,
      "step": 1390
    },
    {
      "epoch": 0.22462896109105496,
      "grad_norm": 0.8063799738883972,
      "learning_rate": 0.0001551098989250762,
      "loss": 1.8722,
      "step": 1400
    },
    {
      "epoch": 0.22623345367027678,
      "grad_norm": 0.4936087727546692,
      "learning_rate": 0.00015478902615113108,
      "loss": 1.6668,
      "step": 1410
    },
    {
      "epoch": 0.2278379462494986,
      "grad_norm": 0.5727702975273132,
      "learning_rate": 0.00015446815337718595,
      "loss": 1.6214,
      "step": 1420
    },
    {
      "epoch": 0.22944243882872042,
      "grad_norm": 0.7012984752655029,
      "learning_rate": 0.00015414728060324082,
      "loss": 1.7518,
      "step": 1430
    },
    {
      "epoch": 0.23104693140794225,
      "grad_norm": 0.6333065032958984,
      "learning_rate": 0.0001538264078292957,
      "loss": 1.5417,
      "step": 1440
    },
    {
      "epoch": 0.23265142398716407,
      "grad_norm": 0.6133058071136475,
      "learning_rate": 0.00015350553505535057,
      "loss": 1.3954,
      "step": 1450
    },
    {
      "epoch": 0.2342559165663859,
      "grad_norm": 0.32819458842277527,
      "learning_rate": 0.00015318466228140542,
      "loss": 1.6129,
      "step": 1460
    },
    {
      "epoch": 0.2358604091456077,
      "grad_norm": 0.8733955025672913,
      "learning_rate": 0.0001528637895074603,
      "loss": 1.6473,
      "step": 1470
    },
    {
      "epoch": 0.23746490172482954,
      "grad_norm": 0.9208136796951294,
      "learning_rate": 0.00015254291673351517,
      "loss": 1.6442,
      "step": 1480
    },
    {
      "epoch": 0.23906939430405133,
      "grad_norm": 0.8026517033576965,
      "learning_rate": 0.00015222204395957004,
      "loss": 1.7227,
      "step": 1490
    },
    {
      "epoch": 0.24067388688327315,
      "grad_norm": 0.7262494564056396,
      "learning_rate": 0.00015190117118562491,
      "loss": 1.6189,
      "step": 1500
    },
    {
      "epoch": 0.24227837946249497,
      "grad_norm": 0.7515296936035156,
      "learning_rate": 0.0001515802984116798,
      "loss": 1.5606,
      "step": 1510
    },
    {
      "epoch": 0.2438828720417168,
      "grad_norm": 0.5507010817527771,
      "learning_rate": 0.00015125942563773466,
      "loss": 1.5651,
      "step": 1520
    },
    {
      "epoch": 0.24548736462093862,
      "grad_norm": 0.6399886012077332,
      "learning_rate": 0.0001509385528637895,
      "loss": 1.5426,
      "step": 1530
    },
    {
      "epoch": 0.24709185720016044,
      "grad_norm": 0.6565406918525696,
      "learning_rate": 0.00015061768008984438,
      "loss": 1.6477,
      "step": 1540
    },
    {
      "epoch": 0.24869634977938226,
      "grad_norm": 0.6251102089881897,
      "learning_rate": 0.00015029680731589926,
      "loss": 1.6377,
      "step": 1550
    },
    {
      "epoch": 0.2503008423586041,
      "grad_norm": 0.8417574763298035,
      "learning_rate": 0.00014997593454195413,
      "loss": 1.7284,
      "step": 1560
    },
    {
      "epoch": 0.2519053349378259,
      "grad_norm": 0.645546019077301,
      "learning_rate": 0.00014965506176800898,
      "loss": 1.6993,
      "step": 1570
    },
    {
      "epoch": 0.25350982751704776,
      "grad_norm": 0.545305073261261,
      "learning_rate": 0.00014933418899406385,
      "loss": 1.8027,
      "step": 1580
    },
    {
      "epoch": 0.25511432009626955,
      "grad_norm": 0.4448450207710266,
      "learning_rate": 0.00014901331622011873,
      "loss": 1.5114,
      "step": 1590
    },
    {
      "epoch": 0.2567188126754914,
      "grad_norm": 0.6229726076126099,
      "learning_rate": 0.0001486924434461736,
      "loss": 1.6011,
      "step": 1600
    },
    {
      "epoch": 0.2583233052547132,
      "grad_norm": 0.7504281401634216,
      "learning_rate": 0.00014837157067222847,
      "loss": 1.6872,
      "step": 1610
    },
    {
      "epoch": 0.259927797833935,
      "grad_norm": 0.5055269598960876,
      "learning_rate": 0.00014805069789828335,
      "loss": 1.5859,
      "step": 1620
    },
    {
      "epoch": 0.26153229041315684,
      "grad_norm": 0.6565330624580383,
      "learning_rate": 0.00014772982512433822,
      "loss": 1.5414,
      "step": 1630
    },
    {
      "epoch": 0.26313678299237864,
      "grad_norm": 0.8226933479309082,
      "learning_rate": 0.00014740895235039307,
      "loss": 1.6228,
      "step": 1640
    },
    {
      "epoch": 0.2647412755716005,
      "grad_norm": 0.6891533136367798,
      "learning_rate": 0.00014708807957644794,
      "loss": 1.7264,
      "step": 1650
    },
    {
      "epoch": 0.2663457681508223,
      "grad_norm": 0.5033508539199829,
      "learning_rate": 0.00014676720680250282,
      "loss": 1.7197,
      "step": 1660
    },
    {
      "epoch": 0.26795026073004413,
      "grad_norm": 0.5730284452438354,
      "learning_rate": 0.00014644633402855766,
      "loss": 1.6527,
      "step": 1670
    },
    {
      "epoch": 0.2695547533092659,
      "grad_norm": 0.4490458369255066,
      "learning_rate": 0.00014612546125461256,
      "loss": 1.5687,
      "step": 1680
    },
    {
      "epoch": 0.2711592458884878,
      "grad_norm": 0.8324654698371887,
      "learning_rate": 0.00014580458848066744,
      "loss": 1.6143,
      "step": 1690
    },
    {
      "epoch": 0.27276373846770957,
      "grad_norm": 0.4939989447593689,
      "learning_rate": 0.0001454837157067223,
      "loss": 1.6018,
      "step": 1700
    },
    {
      "epoch": 0.2743682310469314,
      "grad_norm": 0.4586049020290375,
      "learning_rate": 0.00014516284293277716,
      "loss": 1.5776,
      "step": 1710
    },
    {
      "epoch": 0.2759727236261532,
      "grad_norm": 0.5226346254348755,
      "learning_rate": 0.00014484197015883203,
      "loss": 1.6272,
      "step": 1720
    },
    {
      "epoch": 0.27757721620537507,
      "grad_norm": 0.5561891198158264,
      "learning_rate": 0.0001445210973848869,
      "loss": 1.5783,
      "step": 1730
    },
    {
      "epoch": 0.27918170878459686,
      "grad_norm": 0.4657202363014221,
      "learning_rate": 0.00014420022461094175,
      "loss": 1.5186,
      "step": 1740
    },
    {
      "epoch": 0.2807862013638187,
      "grad_norm": 0.6133905053138733,
      "learning_rate": 0.00014387935183699663,
      "loss": 1.5783,
      "step": 1750
    },
    {
      "epoch": 0.2823906939430405,
      "grad_norm": 0.6218724846839905,
      "learning_rate": 0.0001435584790630515,
      "loss": 1.705,
      "step": 1760
    },
    {
      "epoch": 0.28399518652226236,
      "grad_norm": 0.5091386437416077,
      "learning_rate": 0.00014323760628910637,
      "loss": 1.6658,
      "step": 1770
    },
    {
      "epoch": 0.28559967910148415,
      "grad_norm": 0.6058388352394104,
      "learning_rate": 0.00014291673351516125,
      "loss": 1.4606,
      "step": 1780
    },
    {
      "epoch": 0.287204171680706,
      "grad_norm": 0.4035688042640686,
      "learning_rate": 0.00014259586074121612,
      "loss": 1.4609,
      "step": 1790
    },
    {
      "epoch": 0.2888086642599278,
      "grad_norm": 0.5836511850357056,
      "learning_rate": 0.000142274987967271,
      "loss": 1.7006,
      "step": 1800
    },
    {
      "epoch": 0.29041315683914964,
      "grad_norm": 0.47008490562438965,
      "learning_rate": 0.00014195411519332584,
      "loss": 1.636,
      "step": 1810
    },
    {
      "epoch": 0.29201764941837144,
      "grad_norm": 0.5985816717147827,
      "learning_rate": 0.00014163324241938072,
      "loss": 1.6157,
      "step": 1820
    },
    {
      "epoch": 0.29362214199759323,
      "grad_norm": 0.5106977224349976,
      "learning_rate": 0.0001413123696454356,
      "loss": 1.633,
      "step": 1830
    },
    {
      "epoch": 0.2952266345768151,
      "grad_norm": 0.504979133605957,
      "learning_rate": 0.00014099149687149046,
      "loss": 1.4246,
      "step": 1840
    },
    {
      "epoch": 0.2968311271560369,
      "grad_norm": 0.5301182270050049,
      "learning_rate": 0.0001406706240975453,
      "loss": 1.4781,
      "step": 1850
    },
    {
      "epoch": 0.29843561973525873,
      "grad_norm": 0.6654748916625977,
      "learning_rate": 0.0001403497513236002,
      "loss": 1.6385,
      "step": 1860
    },
    {
      "epoch": 0.3000401123144805,
      "grad_norm": 0.5132201910018921,
      "learning_rate": 0.00014002887854965509,
      "loss": 1.8152,
      "step": 1870
    },
    {
      "epoch": 0.3016446048937024,
      "grad_norm": 0.5509294867515564,
      "learning_rate": 0.00013970800577570993,
      "loss": 1.6882,
      "step": 1880
    },
    {
      "epoch": 0.30324909747292417,
      "grad_norm": 0.48090070486068726,
      "learning_rate": 0.0001393871330017648,
      "loss": 1.5611,
      "step": 1890
    },
    {
      "epoch": 0.304853590052146,
      "grad_norm": 0.6577136516571045,
      "learning_rate": 0.00013906626022781968,
      "loss": 1.7084,
      "step": 1900
    },
    {
      "epoch": 0.3064580826313678,
      "grad_norm": 0.5425799489021301,
      "learning_rate": 0.00013874538745387455,
      "loss": 1.4642,
      "step": 1910
    },
    {
      "epoch": 0.30806257521058966,
      "grad_norm": 0.6224809288978577,
      "learning_rate": 0.0001384245146799294,
      "loss": 1.6102,
      "step": 1920
    },
    {
      "epoch": 0.30966706778981146,
      "grad_norm": 0.492235392332077,
      "learning_rate": 0.00013810364190598427,
      "loss": 1.4925,
      "step": 1930
    },
    {
      "epoch": 0.3112715603690333,
      "grad_norm": 0.8442121744155884,
      "learning_rate": 0.00013778276913203915,
      "loss": 1.5851,
      "step": 1940
    },
    {
      "epoch": 0.3128760529482551,
      "grad_norm": 0.8380377888679504,
      "learning_rate": 0.00013746189635809402,
      "loss": 1.5876,
      "step": 1950
    },
    {
      "epoch": 0.31448054552747695,
      "grad_norm": 0.4565257728099823,
      "learning_rate": 0.0001371410235841489,
      "loss": 1.5043,
      "step": 1960
    },
    {
      "epoch": 0.31608503810669875,
      "grad_norm": 0.4891061782836914,
      "learning_rate": 0.00013682015081020377,
      "loss": 1.6517,
      "step": 1970
    },
    {
      "epoch": 0.3176895306859206,
      "grad_norm": 0.5420975685119629,
      "learning_rate": 0.00013649927803625864,
      "loss": 1.7178,
      "step": 1980
    },
    {
      "epoch": 0.3192940232651424,
      "grad_norm": 1.0363343954086304,
      "learning_rate": 0.0001361784052623135,
      "loss": 1.7067,
      "step": 1990
    },
    {
      "epoch": 0.32089851584436424,
      "grad_norm": 0.7677043080329895,
      "learning_rate": 0.00013585753248836836,
      "loss": 1.709,
      "step": 2000
    },
    {
      "epoch": 0.32250300842358604,
      "grad_norm": 0.6431868076324463,
      "learning_rate": 0.00013553665971442324,
      "loss": 1.4435,
      "step": 2010
    },
    {
      "epoch": 0.3241075010028079,
      "grad_norm": 0.7002491354942322,
      "learning_rate": 0.0001352157869404781,
      "loss": 1.4663,
      "step": 2020
    },
    {
      "epoch": 0.3257119935820297,
      "grad_norm": 0.4876989424228668,
      "learning_rate": 0.00013489491416653296,
      "loss": 1.6779,
      "step": 2030
    },
    {
      "epoch": 0.32731648616125153,
      "grad_norm": 0.6516496539115906,
      "learning_rate": 0.00013457404139258783,
      "loss": 1.4587,
      "step": 2040
    },
    {
      "epoch": 0.3289209787404733,
      "grad_norm": 1.0065714120864868,
      "learning_rate": 0.00013425316861864273,
      "loss": 1.4801,
      "step": 2050
    },
    {
      "epoch": 0.3305254713196951,
      "grad_norm": 0.5158601403236389,
      "learning_rate": 0.00013393229584469758,
      "loss": 1.553,
      "step": 2060
    },
    {
      "epoch": 0.33212996389891697,
      "grad_norm": 0.5632344484329224,
      "learning_rate": 0.00013361142307075245,
      "loss": 1.6515,
      "step": 2070
    },
    {
      "epoch": 0.33373445647813876,
      "grad_norm": 0.7312405705451965,
      "learning_rate": 0.00013329055029680733,
      "loss": 1.7154,
      "step": 2080
    },
    {
      "epoch": 0.3353389490573606,
      "grad_norm": 0.6579000353813171,
      "learning_rate": 0.0001329696775228622,
      "loss": 1.6185,
      "step": 2090
    },
    {
      "epoch": 0.3369434416365824,
      "grad_norm": 0.5576937794685364,
      "learning_rate": 0.00013264880474891705,
      "loss": 1.4459,
      "step": 2100
    },
    {
      "epoch": 0.33854793421580426,
      "grad_norm": 0.59527987241745,
      "learning_rate": 0.00013232793197497192,
      "loss": 1.7053,
      "step": 2110
    },
    {
      "epoch": 0.34015242679502605,
      "grad_norm": 0.37422966957092285,
      "learning_rate": 0.0001320070592010268,
      "loss": 1.7056,
      "step": 2120
    },
    {
      "epoch": 0.3417569193742479,
      "grad_norm": 0.5814105272293091,
      "learning_rate": 0.00013168618642708167,
      "loss": 1.7508,
      "step": 2130
    },
    {
      "epoch": 0.3433614119534697,
      "grad_norm": 0.6714553236961365,
      "learning_rate": 0.00013136531365313654,
      "loss": 1.7695,
      "step": 2140
    },
    {
      "epoch": 0.34496590453269155,
      "grad_norm": 0.49193599820137024,
      "learning_rate": 0.00013104444087919142,
      "loss": 1.4201,
      "step": 2150
    },
    {
      "epoch": 0.34657039711191334,
      "grad_norm": 0.5421782732009888,
      "learning_rate": 0.0001307235681052463,
      "loss": 1.5561,
      "step": 2160
    },
    {
      "epoch": 0.3481748896911352,
      "grad_norm": 0.6226035952568054,
      "learning_rate": 0.00013040269533130114,
      "loss": 1.6017,
      "step": 2170
    },
    {
      "epoch": 0.349779382270357,
      "grad_norm": 0.7535800337791443,
      "learning_rate": 0.000130081822557356,
      "loss": 1.3695,
      "step": 2180
    },
    {
      "epoch": 0.35138387484957884,
      "grad_norm": 0.8149609565734863,
      "learning_rate": 0.0001297609497834109,
      "loss": 1.7112,
      "step": 2190
    },
    {
      "epoch": 0.35298836742880063,
      "grad_norm": 0.6472389698028564,
      "learning_rate": 0.00012944007700946573,
      "loss": 1.6534,
      "step": 2200
    },
    {
      "epoch": 0.3545928600080225,
      "grad_norm": 0.8977332711219788,
      "learning_rate": 0.0001291192042355206,
      "loss": 1.4741,
      "step": 2210
    },
    {
      "epoch": 0.3561973525872443,
      "grad_norm": 0.6139129996299744,
      "learning_rate": 0.00012879833146157548,
      "loss": 1.8561,
      "step": 2220
    },
    {
      "epoch": 0.3578018451664661,
      "grad_norm": 0.4618297219276428,
      "learning_rate": 0.00012847745868763038,
      "loss": 1.6391,
      "step": 2230
    },
    {
      "epoch": 0.3594063377456879,
      "grad_norm": 1.0396194458007812,
      "learning_rate": 0.00012815658591368523,
      "loss": 1.671,
      "step": 2240
    },
    {
      "epoch": 0.36101083032490977,
      "grad_norm": 0.5208600163459778,
      "learning_rate": 0.0001278357131397401,
      "loss": 1.5531,
      "step": 2250
    },
    {
      "epoch": 0.36261532290413157,
      "grad_norm": 0.40562281012535095,
      "learning_rate": 0.00012751484036579498,
      "loss": 1.4415,
      "step": 2260
    },
    {
      "epoch": 0.3642198154833534,
      "grad_norm": 0.8850109577178955,
      "learning_rate": 0.00012719396759184982,
      "loss": 1.5936,
      "step": 2270
    },
    {
      "epoch": 0.3658243080625752,
      "grad_norm": 0.48649460077285767,
      "learning_rate": 0.0001268730948179047,
      "loss": 1.4353,
      "step": 2280
    },
    {
      "epoch": 0.367428800641797,
      "grad_norm": 0.4424438178539276,
      "learning_rate": 0.00012655222204395957,
      "loss": 1.6862,
      "step": 2290
    },
    {
      "epoch": 0.36903329322101885,
      "grad_norm": 0.8997284770011902,
      "learning_rate": 0.00012623134927001445,
      "loss": 1.6437,
      "step": 2300
    },
    {
      "epoch": 0.37063778580024065,
      "grad_norm": 0.5088700652122498,
      "learning_rate": 0.00012591047649606932,
      "loss": 1.7165,
      "step": 2310
    },
    {
      "epoch": 0.3722422783794625,
      "grad_norm": 0.5089598894119263,
      "learning_rate": 0.0001255896037221242,
      "loss": 1.6447,
      "step": 2320
    },
    {
      "epoch": 0.3738467709586843,
      "grad_norm": 0.5863754153251648,
      "learning_rate": 0.00012526873094817907,
      "loss": 1.5661,
      "step": 2330
    },
    {
      "epoch": 0.37545126353790614,
      "grad_norm": 0.47756069898605347,
      "learning_rate": 0.0001249478581742339,
      "loss": 1.7315,
      "step": 2340
    },
    {
      "epoch": 0.37705575611712794,
      "grad_norm": 0.6770239472389221,
      "learning_rate": 0.0001246269854002888,
      "loss": 1.7388,
      "step": 2350
    },
    {
      "epoch": 0.3786602486963498,
      "grad_norm": 0.7587060928344727,
      "learning_rate": 0.00012430611262634366,
      "loss": 1.7359,
      "step": 2360
    },
    {
      "epoch": 0.3802647412755716,
      "grad_norm": 0.6549598574638367,
      "learning_rate": 0.00012398523985239854,
      "loss": 1.6379,
      "step": 2370
    },
    {
      "epoch": 0.38186923385479343,
      "grad_norm": 0.7826295495033264,
      "learning_rate": 0.00012366436707845338,
      "loss": 1.6384,
      "step": 2380
    },
    {
      "epoch": 0.3834737264340152,
      "grad_norm": 0.5292178988456726,
      "learning_rate": 0.00012334349430450826,
      "loss": 1.6061,
      "step": 2390
    },
    {
      "epoch": 0.3850782190132371,
      "grad_norm": 0.7209798097610474,
      "learning_rate": 0.00012302262153056313,
      "loss": 1.7926,
      "step": 2400
    },
    {
      "epoch": 0.38668271159245887,
      "grad_norm": 0.5702222585678101,
      "learning_rate": 0.00012270174875661803,
      "loss": 1.6434,
      "step": 2410
    },
    {
      "epoch": 0.3882872041716807,
      "grad_norm": 0.7532530426979065,
      "learning_rate": 0.00012238087598267288,
      "loss": 1.5731,
      "step": 2420
    },
    {
      "epoch": 0.3898916967509025,
      "grad_norm": 0.7494439482688904,
      "learning_rate": 0.00012206000320872775,
      "loss": 1.4875,
      "step": 2430
    },
    {
      "epoch": 0.39149618933012437,
      "grad_norm": 0.6086689233779907,
      "learning_rate": 0.00012173913043478263,
      "loss": 1.5485,
      "step": 2440
    },
    {
      "epoch": 0.39310068190934616,
      "grad_norm": 0.4896077513694763,
      "learning_rate": 0.00012141825766083747,
      "loss": 1.4112,
      "step": 2450
    },
    {
      "epoch": 0.394705174488568,
      "grad_norm": 0.49366986751556396,
      "learning_rate": 0.00012109738488689235,
      "loss": 1.7321,
      "step": 2460
    },
    {
      "epoch": 0.3963096670677898,
      "grad_norm": 0.7960050702095032,
      "learning_rate": 0.00012077651211294723,
      "loss": 1.475,
      "step": 2470
    },
    {
      "epoch": 0.39791415964701166,
      "grad_norm": 0.5963469743728638,
      "learning_rate": 0.00012045563933900211,
      "loss": 1.5281,
      "step": 2480
    },
    {
      "epoch": 0.39951865222623345,
      "grad_norm": 0.4387144446372986,
      "learning_rate": 0.00012013476656505695,
      "loss": 1.6096,
      "step": 2490
    },
    {
      "epoch": 0.4011231448054553,
      "grad_norm": 0.7144522666931152,
      "learning_rate": 0.00011981389379111183,
      "loss": 1.6157,
      "step": 2500
    },
    {
      "epoch": 0.4027276373846771,
      "grad_norm": 0.28086572885513306,
      "learning_rate": 0.0001194930210171667,
      "loss": 1.6062,
      "step": 2510
    },
    {
      "epoch": 0.4043321299638989,
      "grad_norm": 0.5234121680259705,
      "learning_rate": 0.00011917214824322156,
      "loss": 1.5244,
      "step": 2520
    },
    {
      "epoch": 0.40593662254312074,
      "grad_norm": 0.6640512347221375,
      "learning_rate": 0.00011885127546927644,
      "loss": 1.6676,
      "step": 2530
    },
    {
      "epoch": 0.40754111512234253,
      "grad_norm": 0.7864745855331421,
      "learning_rate": 0.00011853040269533131,
      "loss": 1.5273,
      "step": 2540
    },
    {
      "epoch": 0.4091456077015644,
      "grad_norm": 0.4613713324069977,
      "learning_rate": 0.00011820952992138618,
      "loss": 1.5233,
      "step": 2550
    },
    {
      "epoch": 0.4107501002807862,
      "grad_norm": 0.6245372891426086,
      "learning_rate": 0.00011788865714744104,
      "loss": 1.4852,
      "step": 2560
    },
    {
      "epoch": 0.41235459286000803,
      "grad_norm": 0.6630955338478088,
      "learning_rate": 0.00011756778437349592,
      "loss": 1.5431,
      "step": 2570
    },
    {
      "epoch": 0.4139590854392298,
      "grad_norm": 0.6790159344673157,
      "learning_rate": 0.00011724691159955079,
      "loss": 1.592,
      "step": 2580
    },
    {
      "epoch": 0.4155635780184517,
      "grad_norm": 0.62406986951828,
      "learning_rate": 0.00011692603882560564,
      "loss": 1.5323,
      "step": 2590
    },
    {
      "epoch": 0.41716807059767347,
      "grad_norm": 0.6269447207450867,
      "learning_rate": 0.00011660516605166053,
      "loss": 1.5428,
      "step": 2600
    },
    {
      "epoch": 0.4187725631768953,
      "grad_norm": 0.585418164730072,
      "learning_rate": 0.0001162842932777154,
      "loss": 1.4222,
      "step": 2610
    },
    {
      "epoch": 0.4203770557561171,
      "grad_norm": 0.45809608697891235,
      "learning_rate": 0.00011596342050377027,
      "loss": 1.5906,
      "step": 2620
    },
    {
      "epoch": 0.42198154833533896,
      "grad_norm": 0.6339060664176941,
      "learning_rate": 0.00011564254772982512,
      "loss": 1.6037,
      "step": 2630
    },
    {
      "epoch": 0.42358604091456076,
      "grad_norm": 0.5401502251625061,
      "learning_rate": 0.00011532167495588,
      "loss": 1.5532,
      "step": 2640
    },
    {
      "epoch": 0.4251905334937826,
      "grad_norm": 0.43191587924957275,
      "learning_rate": 0.00011500080218193487,
      "loss": 1.6653,
      "step": 2650
    },
    {
      "epoch": 0.4267950260730044,
      "grad_norm": 0.747560977935791,
      "learning_rate": 0.00011467992940798973,
      "loss": 1.4594,
      "step": 2660
    },
    {
      "epoch": 0.42839951865222625,
      "grad_norm": 0.5991941094398499,
      "learning_rate": 0.0001143590566340446,
      "loss": 1.7196,
      "step": 2670
    },
    {
      "epoch": 0.43000401123144805,
      "grad_norm": 0.48458361625671387,
      "learning_rate": 0.00011403818386009948,
      "loss": 1.3409,
      "step": 2680
    },
    {
      "epoch": 0.4316085038106699,
      "grad_norm": 0.7019787430763245,
      "learning_rate": 0.00011371731108615435,
      "loss": 1.5013,
      "step": 2690
    },
    {
      "epoch": 0.4332129963898917,
      "grad_norm": 0.8148873448371887,
      "learning_rate": 0.00011339643831220921,
      "loss": 1.5395,
      "step": 2700
    },
    {
      "epoch": 0.43481748896911354,
      "grad_norm": 0.7787192463874817,
      "learning_rate": 0.00011307556553826408,
      "loss": 1.5768,
      "step": 2710
    },
    {
      "epoch": 0.43642198154833534,
      "grad_norm": 0.6228867173194885,
      "learning_rate": 0.00011275469276431896,
      "loss": 1.6255,
      "step": 2720
    },
    {
      "epoch": 0.4380264741275572,
      "grad_norm": 0.6969820857048035,
      "learning_rate": 0.00011243381999037382,
      "loss": 1.6099,
      "step": 2730
    },
    {
      "epoch": 0.439630966706779,
      "grad_norm": 0.6455051898956299,
      "learning_rate": 0.00011211294721642869,
      "loss": 1.6592,
      "step": 2740
    },
    {
      "epoch": 0.4412354592860008,
      "grad_norm": 0.6564275622367859,
      "learning_rate": 0.00011179207444248357,
      "loss": 1.6388,
      "step": 2750
    },
    {
      "epoch": 0.4428399518652226,
      "grad_norm": 0.47377151250839233,
      "learning_rate": 0.00011147120166853844,
      "loss": 1.4195,
      "step": 2760
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.40996053814888,
      "learning_rate": 0.00011115032889459329,
      "loss": 1.3924,
      "step": 2770
    },
    {
      "epoch": 0.44604893702366627,
      "grad_norm": 0.9803656935691833,
      "learning_rate": 0.00011082945612064816,
      "loss": 1.4661,
      "step": 2780
    },
    {
      "epoch": 0.44765342960288806,
      "grad_norm": 0.8585478663444519,
      "learning_rate": 0.00011050858334670305,
      "loss": 1.5106,
      "step": 2790
    },
    {
      "epoch": 0.4492579221821099,
      "grad_norm": 0.8918063044548035,
      "learning_rate": 0.0001101877105727579,
      "loss": 1.5262,
      "step": 2800
    },
    {
      "epoch": 0.4508624147613317,
      "grad_norm": 0.6595978140830994,
      "learning_rate": 0.00010986683779881277,
      "loss": 1.4221,
      "step": 2810
    },
    {
      "epoch": 0.45246690734055356,
      "grad_norm": 0.6546085476875305,
      "learning_rate": 0.00010954596502486764,
      "loss": 1.5687,
      "step": 2820
    },
    {
      "epoch": 0.45407139991977535,
      "grad_norm": 0.4958185851573944,
      "learning_rate": 0.00010922509225092252,
      "loss": 1.4795,
      "step": 2830
    },
    {
      "epoch": 0.4556758924989972,
      "grad_norm": 0.6949341297149658,
      "learning_rate": 0.00010890421947697738,
      "loss": 1.3391,
      "step": 2840
    },
    {
      "epoch": 0.457280385078219,
      "grad_norm": 0.5483641624450684,
      "learning_rate": 0.00010858334670303225,
      "loss": 1.5687,
      "step": 2850
    },
    {
      "epoch": 0.45888487765744085,
      "grad_norm": 0.705942690372467,
      "learning_rate": 0.00010826247392908712,
      "loss": 1.7069,
      "step": 2860
    },
    {
      "epoch": 0.46048937023666264,
      "grad_norm": 0.781374454498291,
      "learning_rate": 0.00010794160115514198,
      "loss": 1.4646,
      "step": 2870
    },
    {
      "epoch": 0.4620938628158845,
      "grad_norm": 0.7270205020904541,
      "learning_rate": 0.00010762072838119686,
      "loss": 1.6213,
      "step": 2880
    },
    {
      "epoch": 0.4636983553951063,
      "grad_norm": 0.6445838809013367,
      "learning_rate": 0.00010729985560725173,
      "loss": 1.6492,
      "step": 2890
    },
    {
      "epoch": 0.46530284797432814,
      "grad_norm": 0.555149495601654,
      "learning_rate": 0.0001069789828333066,
      "loss": 1.4794,
      "step": 2900
    },
    {
      "epoch": 0.46690734055354993,
      "grad_norm": 0.6835587024688721,
      "learning_rate": 0.00010665811005936147,
      "loss": 1.6642,
      "step": 2910
    },
    {
      "epoch": 0.4685118331327718,
      "grad_norm": 0.6313014030456543,
      "learning_rate": 0.00010633723728541634,
      "loss": 1.6404,
      "step": 2920
    },
    {
      "epoch": 0.4701163257119936,
      "grad_norm": 0.5652401447296143,
      "learning_rate": 0.00010601636451147121,
      "loss": 1.5034,
      "step": 2930
    },
    {
      "epoch": 0.4717208182912154,
      "grad_norm": 0.8772653937339783,
      "learning_rate": 0.00010569549173752609,
      "loss": 1.6338,
      "step": 2940
    },
    {
      "epoch": 0.4733253108704372,
      "grad_norm": 0.533842146396637,
      "learning_rate": 0.00010537461896358094,
      "loss": 1.6053,
      "step": 2950
    },
    {
      "epoch": 0.47492980344965907,
      "grad_norm": 0.6167129278182983,
      "learning_rate": 0.00010505374618963581,
      "loss": 1.5044,
      "step": 2960
    },
    {
      "epoch": 0.47653429602888087,
      "grad_norm": 0.5421150326728821,
      "learning_rate": 0.0001047328734156907,
      "loss": 1.5312,
      "step": 2970
    },
    {
      "epoch": 0.47813878860810266,
      "grad_norm": 0.8975765705108643,
      "learning_rate": 0.00010441200064174554,
      "loss": 1.4493,
      "step": 2980
    },
    {
      "epoch": 0.4797432811873245,
      "grad_norm": 0.571723461151123,
      "learning_rate": 0.00010409112786780042,
      "loss": 1.5254,
      "step": 2990
    },
    {
      "epoch": 0.4813477737665463,
      "grad_norm": 0.4339660406112671,
      "learning_rate": 0.00010377025509385529,
      "loss": 1.7431,
      "step": 3000
    },
    {
      "epoch": 0.48295226634576816,
      "grad_norm": 0.6656219959259033,
      "learning_rate": 0.00010344938231991016,
      "loss": 1.4982,
      "step": 3010
    },
    {
      "epoch": 0.48455675892498995,
      "grad_norm": 0.5884875059127808,
      "learning_rate": 0.00010312850954596503,
      "loss": 1.4982,
      "step": 3020
    },
    {
      "epoch": 0.4861612515042118,
      "grad_norm": 0.35423529148101807,
      "learning_rate": 0.0001028076367720199,
      "loss": 1.5645,
      "step": 3030
    },
    {
      "epoch": 0.4877657440834336,
      "grad_norm": 0.5120323300361633,
      "learning_rate": 0.00010248676399807477,
      "loss": 1.5269,
      "step": 3040
    },
    {
      "epoch": 0.48937023666265544,
      "grad_norm": 0.5930309891700745,
      "learning_rate": 0.00010216589122412963,
      "loss": 1.5048,
      "step": 3050
    },
    {
      "epoch": 0.49097472924187724,
      "grad_norm": 0.839857280254364,
      "learning_rate": 0.00010184501845018451,
      "loss": 1.48,
      "step": 3060
    },
    {
      "epoch": 0.4925792218210991,
      "grad_norm": 0.5922073721885681,
      "learning_rate": 0.00010152414567623938,
      "loss": 1.6038,
      "step": 3070
    },
    {
      "epoch": 0.4941837144003209,
      "grad_norm": 0.6882144212722778,
      "learning_rate": 0.00010120327290229425,
      "loss": 1.6092,
      "step": 3080
    },
    {
      "epoch": 0.49578820697954273,
      "grad_norm": 0.8950861096382141,
      "learning_rate": 0.0001008824001283491,
      "loss": 1.5247,
      "step": 3090
    },
    {
      "epoch": 0.49739269955876453,
      "grad_norm": 0.8679882884025574,
      "learning_rate": 0.00010056152735440399,
      "loss": 1.3652,
      "step": 3100
    },
    {
      "epoch": 0.4989971921379864,
      "grad_norm": 0.4177021086215973,
      "learning_rate": 0.00010024065458045886,
      "loss": 1.4307,
      "step": 3110
    },
    {
      "epoch": 0.5006016847172082,
      "grad_norm": 0.5267350673675537,
      "learning_rate": 9.991978180651372e-05,
      "loss": 1.5023,
      "step": 3120
    },
    {
      "epoch": 0.50220617729643,
      "grad_norm": 0.7177023887634277,
      "learning_rate": 9.959890903256858e-05,
      "loss": 1.4564,
      "step": 3130
    },
    {
      "epoch": 0.5038106698756518,
      "grad_norm": 0.5702124834060669,
      "learning_rate": 9.927803625862346e-05,
      "loss": 1.4141,
      "step": 3140
    },
    {
      "epoch": 0.5054151624548736,
      "grad_norm": 0.3819965422153473,
      "learning_rate": 9.895716348467833e-05,
      "loss": 1.5665,
      "step": 3150
    },
    {
      "epoch": 0.5070196550340955,
      "grad_norm": 0.9908487200737,
      "learning_rate": 9.86362907107332e-05,
      "loss": 1.5456,
      "step": 3160
    },
    {
      "epoch": 0.5086241476133173,
      "grad_norm": 1.052882194519043,
      "learning_rate": 9.831541793678807e-05,
      "loss": 1.4962,
      "step": 3170
    },
    {
      "epoch": 0.5102286401925391,
      "grad_norm": 0.5426758527755737,
      "learning_rate": 9.799454516284293e-05,
      "loss": 1.4831,
      "step": 3180
    },
    {
      "epoch": 0.5118331327717609,
      "grad_norm": 0.613970935344696,
      "learning_rate": 9.767367238889781e-05,
      "loss": 1.6633,
      "step": 3190
    },
    {
      "epoch": 0.5134376253509828,
      "grad_norm": 0.7904638051986694,
      "learning_rate": 9.735279961495267e-05,
      "loss": 1.5718,
      "step": 3200
    },
    {
      "epoch": 0.5150421179302046,
      "grad_norm": 0.633767306804657,
      "learning_rate": 9.703192684100755e-05,
      "loss": 1.647,
      "step": 3210
    },
    {
      "epoch": 0.5166466105094264,
      "grad_norm": 0.7576586604118347,
      "learning_rate": 9.671105406706241e-05,
      "loss": 1.4091,
      "step": 3220
    },
    {
      "epoch": 0.5182511030886482,
      "grad_norm": 0.8457580208778381,
      "learning_rate": 9.639018129311728e-05,
      "loss": 1.4721,
      "step": 3230
    },
    {
      "epoch": 0.51985559566787,
      "grad_norm": 1.0074951648712158,
      "learning_rate": 9.606930851917216e-05,
      "loss": 1.6082,
      "step": 3240
    },
    {
      "epoch": 0.5214600882470919,
      "grad_norm": 0.7569481134414673,
      "learning_rate": 9.574843574522703e-05,
      "loss": 1.5825,
      "step": 3250
    },
    {
      "epoch": 0.5230645808263137,
      "grad_norm": 0.9717037081718445,
      "learning_rate": 9.542756297128189e-05,
      "loss": 1.4003,
      "step": 3260
    },
    {
      "epoch": 0.5246690734055355,
      "grad_norm": 0.6950996518135071,
      "learning_rate": 9.510669019733675e-05,
      "loss": 1.6099,
      "step": 3270
    },
    {
      "epoch": 0.5262735659847573,
      "grad_norm": 0.5112638473510742,
      "learning_rate": 9.478581742339164e-05,
      "loss": 1.5893,
      "step": 3280
    },
    {
      "epoch": 0.5278780585639792,
      "grad_norm": 0.7163785696029663,
      "learning_rate": 9.44649446494465e-05,
      "loss": 1.4755,
      "step": 3290
    },
    {
      "epoch": 0.529482551143201,
      "grad_norm": 0.6543883085250854,
      "learning_rate": 9.414407187550137e-05,
      "loss": 1.5674,
      "step": 3300
    },
    {
      "epoch": 0.5310870437224228,
      "grad_norm": 0.5765068531036377,
      "learning_rate": 9.382319910155623e-05,
      "loss": 1.6613,
      "step": 3310
    },
    {
      "epoch": 0.5326915363016446,
      "grad_norm": 0.9102649092674255,
      "learning_rate": 9.35023263276111e-05,
      "loss": 1.5506,
      "step": 3320
    },
    {
      "epoch": 0.5342960288808665,
      "grad_norm": 0.6059777140617371,
      "learning_rate": 9.318145355366598e-05,
      "loss": 1.5474,
      "step": 3330
    },
    {
      "epoch": 0.5359005214600883,
      "grad_norm": 0.5535997748374939,
      "learning_rate": 9.286058077972084e-05,
      "loss": 1.6733,
      "step": 3340
    },
    {
      "epoch": 0.5375050140393101,
      "grad_norm": 0.5993005037307739,
      "learning_rate": 9.253970800577571e-05,
      "loss": 1.5161,
      "step": 3350
    },
    {
      "epoch": 0.5391095066185319,
      "grad_norm": 0.48182302713394165,
      "learning_rate": 9.221883523183057e-05,
      "loss": 1.5987,
      "step": 3360
    },
    {
      "epoch": 0.5407139991977538,
      "grad_norm": 0.6896758079528809,
      "learning_rate": 9.189796245788546e-05,
      "loss": 1.6686,
      "step": 3370
    },
    {
      "epoch": 0.5423184917769756,
      "grad_norm": 0.4876813292503357,
      "learning_rate": 9.157708968394032e-05,
      "loss": 1.3144,
      "step": 3380
    },
    {
      "epoch": 0.5439229843561973,
      "grad_norm": 0.6594116687774658,
      "learning_rate": 9.12562169099952e-05,
      "loss": 1.5499,
      "step": 3390
    },
    {
      "epoch": 0.5455274769354191,
      "grad_norm": 1.0736714601516724,
      "learning_rate": 9.093534413605006e-05,
      "loss": 1.5515,
      "step": 3400
    },
    {
      "epoch": 0.547131969514641,
      "grad_norm": 0.6815177798271179,
      "learning_rate": 9.061447136210493e-05,
      "loss": 1.5731,
      "step": 3410
    },
    {
      "epoch": 0.5487364620938628,
      "grad_norm": 0.5234796404838562,
      "learning_rate": 9.02935985881598e-05,
      "loss": 1.5161,
      "step": 3420
    },
    {
      "epoch": 0.5503409546730846,
      "grad_norm": 0.7663474082946777,
      "learning_rate": 8.997272581421466e-05,
      "loss": 1.7912,
      "step": 3430
    },
    {
      "epoch": 0.5519454472523064,
      "grad_norm": 0.7076428532600403,
      "learning_rate": 8.965185304026954e-05,
      "loss": 1.6378,
      "step": 3440
    },
    {
      "epoch": 0.5535499398315282,
      "grad_norm": 0.4506141245365143,
      "learning_rate": 8.93309802663244e-05,
      "loss": 1.4981,
      "step": 3450
    },
    {
      "epoch": 0.5551544324107501,
      "grad_norm": 0.8431974649429321,
      "learning_rate": 8.901010749237929e-05,
      "loss": 1.5655,
      "step": 3460
    },
    {
      "epoch": 0.5567589249899719,
      "grad_norm": 0.5423415899276733,
      "learning_rate": 8.868923471843415e-05,
      "loss": 1.5687,
      "step": 3470
    },
    {
      "epoch": 0.5583634175691937,
      "grad_norm": 0.7058682441711426,
      "learning_rate": 8.836836194448902e-05,
      "loss": 1.7354,
      "step": 3480
    },
    {
      "epoch": 0.5599679101484155,
      "grad_norm": 0.5626120567321777,
      "learning_rate": 8.804748917054388e-05,
      "loss": 1.7187,
      "step": 3490
    },
    {
      "epoch": 0.5615724027276374,
      "grad_norm": 0.6530567407608032,
      "learning_rate": 8.772661639659875e-05,
      "loss": 1.4954,
      "step": 3500
    },
    {
      "epoch": 0.5631768953068592,
      "grad_norm": 0.4367051124572754,
      "learning_rate": 8.740574362265363e-05,
      "loss": 1.5068,
      "step": 3510
    },
    {
      "epoch": 0.564781387886081,
      "grad_norm": 0.7512232661247253,
      "learning_rate": 8.708487084870849e-05,
      "loss": 1.5562,
      "step": 3520
    },
    {
      "epoch": 0.5663858804653028,
      "grad_norm": 0.5488330125808716,
      "learning_rate": 8.676399807476336e-05,
      "loss": 1.5373,
      "step": 3530
    },
    {
      "epoch": 0.5679903730445247,
      "grad_norm": 0.7574217915534973,
      "learning_rate": 8.644312530081822e-05,
      "loss": 1.8154,
      "step": 3540
    },
    {
      "epoch": 0.5695948656237465,
      "grad_norm": 0.6091497540473938,
      "learning_rate": 8.612225252687311e-05,
      "loss": 1.6284,
      "step": 3550
    },
    {
      "epoch": 0.5711993582029683,
      "grad_norm": 0.7172434329986572,
      "learning_rate": 8.580137975292797e-05,
      "loss": 1.7323,
      "step": 3560
    },
    {
      "epoch": 0.5728038507821901,
      "grad_norm": 0.7475478649139404,
      "learning_rate": 8.548050697898283e-05,
      "loss": 1.5617,
      "step": 3570
    },
    {
      "epoch": 0.574408343361412,
      "grad_norm": 0.5941392183303833,
      "learning_rate": 8.51596342050377e-05,
      "loss": 1.6131,
      "step": 3580
    },
    {
      "epoch": 0.5760128359406338,
      "grad_norm": 0.3749290704727173,
      "learning_rate": 8.483876143109258e-05,
      "loss": 1.3364,
      "step": 3590
    },
    {
      "epoch": 0.5776173285198556,
      "grad_norm": 0.6011642217636108,
      "learning_rate": 8.451788865714745e-05,
      "loss": 1.6248,
      "step": 3600
    },
    {
      "epoch": 0.5792218210990774,
      "grad_norm": 0.38523173332214355,
      "learning_rate": 8.419701588320231e-05,
      "loss": 1.5652,
      "step": 3610
    },
    {
      "epoch": 0.5808263136782993,
      "grad_norm": 0.9076216220855713,
      "learning_rate": 8.387614310925719e-05,
      "loss": 1.5783,
      "step": 3620
    },
    {
      "epoch": 0.5824308062575211,
      "grad_norm": 0.7605106830596924,
      "learning_rate": 8.355527033531205e-05,
      "loss": 1.3972,
      "step": 3630
    },
    {
      "epoch": 0.5840352988367429,
      "grad_norm": 0.8341193199157715,
      "learning_rate": 8.323439756136692e-05,
      "loss": 1.5402,
      "step": 3640
    },
    {
      "epoch": 0.5856397914159647,
      "grad_norm": 0.5550037622451782,
      "learning_rate": 8.29135247874218e-05,
      "loss": 1.604,
      "step": 3650
    },
    {
      "epoch": 0.5872442839951865,
      "grad_norm": 0.5797702074050903,
      "learning_rate": 8.259265201347665e-05,
      "loss": 1.8414,
      "step": 3660
    },
    {
      "epoch": 0.5888487765744084,
      "grad_norm": 1.0889140367507935,
      "learning_rate": 8.227177923953153e-05,
      "loss": 1.3037,
      "step": 3670
    },
    {
      "epoch": 0.5904532691536302,
      "grad_norm": 0.6421298980712891,
      "learning_rate": 8.19509064655864e-05,
      "loss": 1.5801,
      "step": 3680
    },
    {
      "epoch": 0.592057761732852,
      "grad_norm": 0.5088265538215637,
      "learning_rate": 8.163003369164128e-05,
      "loss": 1.4745,
      "step": 3690
    },
    {
      "epoch": 0.5936622543120738,
      "grad_norm": 0.7336844205856323,
      "learning_rate": 8.130916091769614e-05,
      "loss": 1.495,
      "step": 3700
    },
    {
      "epoch": 0.5952667468912957,
      "grad_norm": 0.4363652765750885,
      "learning_rate": 8.098828814375101e-05,
      "loss": 1.498,
      "step": 3710
    },
    {
      "epoch": 0.5968712394705175,
      "grad_norm": 0.5722938179969788,
      "learning_rate": 8.066741536980587e-05,
      "loss": 1.6444,
      "step": 3720
    },
    {
      "epoch": 0.5984757320497393,
      "grad_norm": 0.553973913192749,
      "learning_rate": 8.034654259586074e-05,
      "loss": 1.5347,
      "step": 3730
    },
    {
      "epoch": 0.600080224628961,
      "grad_norm": 0.6670509576797485,
      "learning_rate": 8.002566982191562e-05,
      "loss": 1.6276,
      "step": 3740
    },
    {
      "epoch": 0.601684717208183,
      "grad_norm": 0.7124415636062622,
      "learning_rate": 7.970479704797048e-05,
      "loss": 1.5393,
      "step": 3750
    },
    {
      "epoch": 0.6032892097874047,
      "grad_norm": 0.3658709228038788,
      "learning_rate": 7.938392427402535e-05,
      "loss": 1.3779,
      "step": 3760
    },
    {
      "epoch": 0.6048937023666265,
      "grad_norm": 0.7190360426902771,
      "learning_rate": 7.906305150008023e-05,
      "loss": 1.7361,
      "step": 3770
    },
    {
      "epoch": 0.6064981949458483,
      "grad_norm": 0.7631715536117554,
      "learning_rate": 7.87421787261351e-05,
      "loss": 1.7061,
      "step": 3780
    },
    {
      "epoch": 0.6081026875250702,
      "grad_norm": 0.7354585528373718,
      "learning_rate": 7.842130595218996e-05,
      "loss": 1.3807,
      "step": 3790
    },
    {
      "epoch": 0.609707180104292,
      "grad_norm": 0.8295516967773438,
      "learning_rate": 7.810043317824482e-05,
      "loss": 1.7076,
      "step": 3800
    },
    {
      "epoch": 0.6113116726835138,
      "grad_norm": 0.39141735434532166,
      "learning_rate": 7.77795604042997e-05,
      "loss": 1.4347,
      "step": 3810
    },
    {
      "epoch": 0.6129161652627356,
      "grad_norm": 0.4014708399772644,
      "learning_rate": 7.745868763035457e-05,
      "loss": 1.617,
      "step": 3820
    },
    {
      "epoch": 0.6145206578419575,
      "grad_norm": 0.5024163722991943,
      "learning_rate": 7.713781485640944e-05,
      "loss": 1.6306,
      "step": 3830
    },
    {
      "epoch": 0.6161251504211793,
      "grad_norm": 0.9097760915756226,
      "learning_rate": 7.68169420824643e-05,
      "loss": 1.5185,
      "step": 3840
    },
    {
      "epoch": 0.6177296430004011,
      "grad_norm": 0.81366366147995,
      "learning_rate": 7.649606930851918e-05,
      "loss": 1.5328,
      "step": 3850
    },
    {
      "epoch": 0.6193341355796229,
      "grad_norm": 1.3028035163879395,
      "learning_rate": 7.617519653457405e-05,
      "loss": 1.5632,
      "step": 3860
    },
    {
      "epoch": 0.6209386281588448,
      "grad_norm": 0.7469263672828674,
      "learning_rate": 7.585432376062891e-05,
      "loss": 1.7437,
      "step": 3870
    },
    {
      "epoch": 0.6225431207380666,
      "grad_norm": 0.6782803535461426,
      "learning_rate": 7.553345098668379e-05,
      "loss": 1.5706,
      "step": 3880
    },
    {
      "epoch": 0.6241476133172884,
      "grad_norm": 0.6957464814186096,
      "learning_rate": 7.521257821273865e-05,
      "loss": 1.4794,
      "step": 3890
    },
    {
      "epoch": 0.6257521058965102,
      "grad_norm": 0.5972074270248413,
      "learning_rate": 7.489170543879352e-05,
      "loss": 1.6751,
      "step": 3900
    },
    {
      "epoch": 0.627356598475732,
      "grad_norm": 0.8221641778945923,
      "learning_rate": 7.45708326648484e-05,
      "loss": 1.619,
      "step": 3910
    },
    {
      "epoch": 0.6289610910549539,
      "grad_norm": 0.6571446657180786,
      "learning_rate": 7.424995989090327e-05,
      "loss": 1.6064,
      "step": 3920
    },
    {
      "epoch": 0.6305655836341757,
      "grad_norm": 0.8439871072769165,
      "learning_rate": 7.392908711695813e-05,
      "loss": 1.3681,
      "step": 3930
    },
    {
      "epoch": 0.6321700762133975,
      "grad_norm": 0.7509510517120361,
      "learning_rate": 7.360821434301299e-05,
      "loss": 1.328,
      "step": 3940
    },
    {
      "epoch": 0.6337745687926193,
      "grad_norm": 0.853447675704956,
      "learning_rate": 7.328734156906788e-05,
      "loss": 1.3767,
      "step": 3950
    },
    {
      "epoch": 0.6353790613718412,
      "grad_norm": 0.8944651484489441,
      "learning_rate": 7.296646879512274e-05,
      "loss": 1.4477,
      "step": 3960
    },
    {
      "epoch": 0.636983553951063,
      "grad_norm": 0.48986464738845825,
      "learning_rate": 7.264559602117761e-05,
      "loss": 1.4396,
      "step": 3970
    },
    {
      "epoch": 0.6385880465302848,
      "grad_norm": 0.575263261795044,
      "learning_rate": 7.232472324723247e-05,
      "loss": 1.3866,
      "step": 3980
    },
    {
      "epoch": 0.6401925391095066,
      "grad_norm": 0.5042412877082825,
      "learning_rate": 7.200385047328734e-05,
      "loss": 1.4222,
      "step": 3990
    },
    {
      "epoch": 0.6417970316887285,
      "grad_norm": 0.6863070726394653,
      "learning_rate": 7.168297769934222e-05,
      "loss": 1.4544,
      "step": 4000
    },
    {
      "epoch": 0.6434015242679503,
      "grad_norm": 0.8116100430488586,
      "learning_rate": 7.136210492539709e-05,
      "loss": 1.4688,
      "step": 4010
    },
    {
      "epoch": 0.6450060168471721,
      "grad_norm": 0.9162916541099548,
      "learning_rate": 7.104123215145195e-05,
      "loss": 1.6083,
      "step": 4020
    },
    {
      "epoch": 0.6466105094263939,
      "grad_norm": 0.6804922819137573,
      "learning_rate": 7.072035937750681e-05,
      "loss": 1.5379,
      "step": 4030
    },
    {
      "epoch": 0.6482150020056158,
      "grad_norm": 0.5355374813079834,
      "learning_rate": 7.03994866035617e-05,
      "loss": 1.6815,
      "step": 4040
    },
    {
      "epoch": 0.6498194945848376,
      "grad_norm": 0.615565299987793,
      "learning_rate": 7.007861382961656e-05,
      "loss": 1.5751,
      "step": 4050
    },
    {
      "epoch": 0.6514239871640594,
      "grad_norm": 0.8551216721534729,
      "learning_rate": 6.975774105567143e-05,
      "loss": 1.4436,
      "step": 4060
    },
    {
      "epoch": 0.6530284797432812,
      "grad_norm": 0.9022431373596191,
      "learning_rate": 6.94368682817263e-05,
      "loss": 1.7802,
      "step": 4070
    },
    {
      "epoch": 0.6546329723225031,
      "grad_norm": 0.6944996118545532,
      "learning_rate": 6.911599550778117e-05,
      "loss": 1.6742,
      "step": 4080
    },
    {
      "epoch": 0.6562374649017249,
      "grad_norm": 0.50541090965271,
      "learning_rate": 6.879512273383604e-05,
      "loss": 1.5203,
      "step": 4090
    },
    {
      "epoch": 0.6578419574809466,
      "grad_norm": 0.7559130787849426,
      "learning_rate": 6.84742499598909e-05,
      "loss": 1.5595,
      "step": 4100
    },
    {
      "epoch": 0.6594464500601684,
      "grad_norm": 0.8824014067649841,
      "learning_rate": 6.815337718594578e-05,
      "loss": 1.3973,
      "step": 4110
    },
    {
      "epoch": 0.6610509426393902,
      "grad_norm": 0.8671344518661499,
      "learning_rate": 6.783250441200064e-05,
      "loss": 1.6595,
      "step": 4120
    },
    {
      "epoch": 0.6626554352186121,
      "grad_norm": 0.4775891900062561,
      "learning_rate": 6.751163163805552e-05,
      "loss": 1.4081,
      "step": 4130
    },
    {
      "epoch": 0.6642599277978339,
      "grad_norm": 1.036381483078003,
      "learning_rate": 6.719075886411038e-05,
      "loss": 1.5695,
      "step": 4140
    },
    {
      "epoch": 0.6658644203770557,
      "grad_norm": 0.9454764127731323,
      "learning_rate": 6.686988609016526e-05,
      "loss": 1.4381,
      "step": 4150
    },
    {
      "epoch": 0.6674689129562775,
      "grad_norm": 0.6405451893806458,
      "learning_rate": 6.654901331622012e-05,
      "loss": 1.6393,
      "step": 4160
    },
    {
      "epoch": 0.6690734055354994,
      "grad_norm": 1.1798784732818604,
      "learning_rate": 6.622814054227499e-05,
      "loss": 1.4252,
      "step": 4170
    },
    {
      "epoch": 0.6706778981147212,
      "grad_norm": 0.6509971618652344,
      "learning_rate": 6.590726776832987e-05,
      "loss": 1.6791,
      "step": 4180
    },
    {
      "epoch": 0.672282390693943,
      "grad_norm": 0.545407235622406,
      "learning_rate": 6.558639499438473e-05,
      "loss": 1.3816,
      "step": 4190
    },
    {
      "epoch": 0.6738868832731648,
      "grad_norm": 0.529946506023407,
      "learning_rate": 6.52655222204396e-05,
      "loss": 1.7672,
      "step": 4200
    },
    {
      "epoch": 0.6754913758523867,
      "grad_norm": 0.7104240655899048,
      "learning_rate": 6.494464944649446e-05,
      "loss": 1.4176,
      "step": 4210
    },
    {
      "epoch": 0.6770958684316085,
      "grad_norm": 0.8743439316749573,
      "learning_rate": 6.462377667254933e-05,
      "loss": 1.5496,
      "step": 4220
    },
    {
      "epoch": 0.6787003610108303,
      "grad_norm": 0.6607592105865479,
      "learning_rate": 6.430290389860421e-05,
      "loss": 1.4795,
      "step": 4230
    },
    {
      "epoch": 0.6803048535900521,
      "grad_norm": 0.6948530673980713,
      "learning_rate": 6.398203112465908e-05,
      "loss": 1.5347,
      "step": 4240
    },
    {
      "epoch": 0.681909346169274,
      "grad_norm": 0.5989628434181213,
      "learning_rate": 6.366115835071394e-05,
      "loss": 1.2948,
      "step": 4250
    },
    {
      "epoch": 0.6835138387484958,
      "grad_norm": 0.6463784575462341,
      "learning_rate": 6.334028557676882e-05,
      "loss": 1.6953,
      "step": 4260
    },
    {
      "epoch": 0.6851183313277176,
      "grad_norm": 0.5740833282470703,
      "learning_rate": 6.301941280282369e-05,
      "loss": 1.5607,
      "step": 4270
    },
    {
      "epoch": 0.6867228239069394,
      "grad_norm": 0.47370925545692444,
      "learning_rate": 6.269854002887855e-05,
      "loss": 1.3204,
      "step": 4280
    },
    {
      "epoch": 0.6883273164861613,
      "grad_norm": 0.8105477094650269,
      "learning_rate": 6.237766725493342e-05,
      "loss": 1.3038,
      "step": 4290
    },
    {
      "epoch": 0.6899318090653831,
      "grad_norm": 0.34146156907081604,
      "learning_rate": 6.205679448098828e-05,
      "loss": 1.4736,
      "step": 4300
    },
    {
      "epoch": 0.6915363016446049,
      "grad_norm": 0.6083927750587463,
      "learning_rate": 6.173592170704316e-05,
      "loss": 1.513,
      "step": 4310
    },
    {
      "epoch": 0.6931407942238267,
      "grad_norm": 0.677801787853241,
      "learning_rate": 6.141504893309803e-05,
      "loss": 1.5855,
      "step": 4320
    },
    {
      "epoch": 0.6947452868030486,
      "grad_norm": 0.7488950490951538,
      "learning_rate": 6.109417615915289e-05,
      "loss": 1.4882,
      "step": 4330
    },
    {
      "epoch": 0.6963497793822704,
      "grad_norm": 1.2130292654037476,
      "learning_rate": 6.0773303385207767e-05,
      "loss": 1.6742,
      "step": 4340
    },
    {
      "epoch": 0.6979542719614922,
      "grad_norm": 0.7110220789909363,
      "learning_rate": 6.0452430611262634e-05,
      "loss": 1.7396,
      "step": 4350
    },
    {
      "epoch": 0.699558764540714,
      "grad_norm": 0.6665270328521729,
      "learning_rate": 6.013155783731751e-05,
      "loss": 1.4648,
      "step": 4360
    },
    {
      "epoch": 0.7011632571199358,
      "grad_norm": 0.8662271499633789,
      "learning_rate": 5.9810685063372375e-05,
      "loss": 1.554,
      "step": 4370
    },
    {
      "epoch": 0.7027677496991577,
      "grad_norm": 0.543958842754364,
      "learning_rate": 5.948981228942725e-05,
      "loss": 1.3439,
      "step": 4380
    },
    {
      "epoch": 0.7043722422783795,
      "grad_norm": 0.6508810520172119,
      "learning_rate": 5.9168939515482116e-05,
      "loss": 1.4535,
      "step": 4390
    },
    {
      "epoch": 0.7059767348576013,
      "grad_norm": 0.7086533308029175,
      "learning_rate": 5.8848066741536976e-05,
      "loss": 1.3422,
      "step": 4400
    },
    {
      "epoch": 0.7075812274368231,
      "grad_norm": 0.6695998311042786,
      "learning_rate": 5.8527193967591857e-05,
      "loss": 1.4222,
      "step": 4410
    },
    {
      "epoch": 0.709185720016045,
      "grad_norm": 0.5926269888877869,
      "learning_rate": 5.820632119364672e-05,
      "loss": 1.2628,
      "step": 4420
    },
    {
      "epoch": 0.7107902125952668,
      "grad_norm": 0.586911141872406,
      "learning_rate": 5.788544841970159e-05,
      "loss": 1.5997,
      "step": 4430
    },
    {
      "epoch": 0.7123947051744886,
      "grad_norm": 0.7436565160751343,
      "learning_rate": 5.756457564575646e-05,
      "loss": 1.7477,
      "step": 4440
    },
    {
      "epoch": 0.7139991977537103,
      "grad_norm": 0.45458984375,
      "learning_rate": 5.724370287181133e-05,
      "loss": 1.3782,
      "step": 4450
    },
    {
      "epoch": 0.7156036903329323,
      "grad_norm": 0.5720877647399902,
      "learning_rate": 5.69228300978662e-05,
      "loss": 1.6556,
      "step": 4460
    },
    {
      "epoch": 0.717208182912154,
      "grad_norm": 0.49324193596839905,
      "learning_rate": 5.660195732392107e-05,
      "loss": 1.4042,
      "step": 4470
    },
    {
      "epoch": 0.7188126754913758,
      "grad_norm": 0.914692223072052,
      "learning_rate": 5.628108454997594e-05,
      "loss": 1.6684,
      "step": 4480
    },
    {
      "epoch": 0.7204171680705976,
      "grad_norm": 0.5108540058135986,
      "learning_rate": 5.59602117760308e-05,
      "loss": 1.503,
      "step": 4490
    },
    {
      "epoch": 0.7220216606498195,
      "grad_norm": 0.5685701370239258,
      "learning_rate": 5.563933900208568e-05,
      "loss": 1.4546,
      "step": 4500
    },
    {
      "epoch": 0.7236261532290413,
      "grad_norm": 0.7125024199485779,
      "learning_rate": 5.531846622814054e-05,
      "loss": 1.681,
      "step": 4510
    },
    {
      "epoch": 0.7252306458082631,
      "grad_norm": 0.5444106459617615,
      "learning_rate": 5.4997593454195415e-05,
      "loss": 1.5803,
      "step": 4520
    },
    {
      "epoch": 0.7268351383874849,
      "grad_norm": 0.5861436724662781,
      "learning_rate": 5.467672068025028e-05,
      "loss": 1.4503,
      "step": 4530
    },
    {
      "epoch": 0.7284396309667068,
      "grad_norm": 1.086201548576355,
      "learning_rate": 5.4355847906305156e-05,
      "loss": 1.6353,
      "step": 4540
    },
    {
      "epoch": 0.7300441235459286,
      "grad_norm": 0.5262022018432617,
      "learning_rate": 5.403497513236002e-05,
      "loss": 1.3002,
      "step": 4550
    },
    {
      "epoch": 0.7316486161251504,
      "grad_norm": 0.5894297361373901,
      "learning_rate": 5.3714102358414883e-05,
      "loss": 1.4794,
      "step": 4560
    },
    {
      "epoch": 0.7332531087043722,
      "grad_norm": 0.7318147420883179,
      "learning_rate": 5.3393229584469764e-05,
      "loss": 1.6434,
      "step": 4570
    },
    {
      "epoch": 0.734857601283594,
      "grad_norm": 0.480058878660202,
      "learning_rate": 5.3072356810524624e-05,
      "loss": 1.4745,
      "step": 4580
    },
    {
      "epoch": 0.7364620938628159,
      "grad_norm": 1.003372311592102,
      "learning_rate": 5.27514840365795e-05,
      "loss": 1.4554,
      "step": 4590
    },
    {
      "epoch": 0.7380665864420377,
      "grad_norm": 0.7654954195022583,
      "learning_rate": 5.2430611262634365e-05,
      "loss": 1.5107,
      "step": 4600
    },
    {
      "epoch": 0.7396710790212595,
      "grad_norm": 0.600762128829956,
      "learning_rate": 5.210973848868924e-05,
      "loss": 1.5771,
      "step": 4610
    },
    {
      "epoch": 0.7412755716004813,
      "grad_norm": 0.8644028306007385,
      "learning_rate": 5.1788865714744106e-05,
      "loss": 1.6109,
      "step": 4620
    },
    {
      "epoch": 0.7428800641797032,
      "grad_norm": 0.5806650519371033,
      "learning_rate": 5.1467992940798973e-05,
      "loss": 1.4777,
      "step": 4630
    },
    {
      "epoch": 0.744484556758925,
      "grad_norm": 0.7585260272026062,
      "learning_rate": 5.114712016685385e-05,
      "loss": 1.5496,
      "step": 4640
    },
    {
      "epoch": 0.7460890493381468,
      "grad_norm": 0.8694347143173218,
      "learning_rate": 5.082624739290871e-05,
      "loss": 1.5745,
      "step": 4650
    },
    {
      "epoch": 0.7476935419173686,
      "grad_norm": 0.4649813771247864,
      "learning_rate": 5.050537461896359e-05,
      "loss": 1.4296,
      "step": 4660
    },
    {
      "epoch": 0.7492980344965905,
      "grad_norm": 0.981113612651825,
      "learning_rate": 5.018450184501845e-05,
      "loss": 1.4951,
      "step": 4670
    },
    {
      "epoch": 0.7509025270758123,
      "grad_norm": 0.8952191472053528,
      "learning_rate": 4.986362907107332e-05,
      "loss": 1.582,
      "step": 4680
    },
    {
      "epoch": 0.7525070196550341,
      "grad_norm": 0.8877620100975037,
      "learning_rate": 4.954275629712819e-05,
      "loss": 1.624,
      "step": 4690
    },
    {
      "epoch": 0.7541115122342559,
      "grad_norm": 0.8052526712417603,
      "learning_rate": 4.922188352318306e-05,
      "loss": 1.4286,
      "step": 4700
    },
    {
      "epoch": 0.7557160048134778,
      "grad_norm": 0.6184908747673035,
      "learning_rate": 4.890101074923793e-05,
      "loss": 1.5027,
      "step": 4710
    },
    {
      "epoch": 0.7573204973926996,
      "grad_norm": 0.8789324164390564,
      "learning_rate": 4.85801379752928e-05,
      "loss": 1.4567,
      "step": 4720
    },
    {
      "epoch": 0.7589249899719214,
      "grad_norm": 0.5530652403831482,
      "learning_rate": 4.825926520134767e-05,
      "loss": 1.4075,
      "step": 4730
    },
    {
      "epoch": 0.7605294825511432,
      "grad_norm": 0.9497061967849731,
      "learning_rate": 4.793839242740254e-05,
      "loss": 1.8114,
      "step": 4740
    },
    {
      "epoch": 0.7621339751303651,
      "grad_norm": 0.5183262825012207,
      "learning_rate": 4.7617519653457406e-05,
      "loss": 1.4892,
      "step": 4750
    },
    {
      "epoch": 0.7637384677095869,
      "grad_norm": 0.645215630531311,
      "learning_rate": 4.729664687951227e-05,
      "loss": 1.4378,
      "step": 4760
    },
    {
      "epoch": 0.7653429602888087,
      "grad_norm": 0.5571088790893555,
      "learning_rate": 4.697577410556715e-05,
      "loss": 1.7273,
      "step": 4770
    },
    {
      "epoch": 0.7669474528680305,
      "grad_norm": 0.6127004623413086,
      "learning_rate": 4.6654901331622014e-05,
      "loss": 1.3471,
      "step": 4780
    },
    {
      "epoch": 0.7685519454472524,
      "grad_norm": 0.7501471638679504,
      "learning_rate": 4.633402855767688e-05,
      "loss": 1.6209,
      "step": 4790
    },
    {
      "epoch": 0.7701564380264742,
      "grad_norm": 0.40581512451171875,
      "learning_rate": 4.6013155783731755e-05,
      "loss": 1.445,
      "step": 4800
    },
    {
      "epoch": 0.771760930605696,
      "grad_norm": 0.897953450679779,
      "learning_rate": 4.569228300978662e-05,
      "loss": 1.5786,
      "step": 4810
    },
    {
      "epoch": 0.7733654231849177,
      "grad_norm": 0.695181131362915,
      "learning_rate": 4.537141023584149e-05,
      "loss": 1.462,
      "step": 4820
    },
    {
      "epoch": 0.7749699157641395,
      "grad_norm": 0.9547716975212097,
      "learning_rate": 4.5050537461896356e-05,
      "loss": 1.3778,
      "step": 4830
    },
    {
      "epoch": 0.7765744083433614,
      "grad_norm": 0.4244387149810791,
      "learning_rate": 4.472966468795123e-05,
      "loss": 1.3408,
      "step": 4840
    },
    {
      "epoch": 0.7781789009225832,
      "grad_norm": 0.7185670137405396,
      "learning_rate": 4.44087919140061e-05,
      "loss": 1.4052,
      "step": 4850
    },
    {
      "epoch": 0.779783393501805,
      "grad_norm": 1.0715895891189575,
      "learning_rate": 4.408791914006097e-05,
      "loss": 1.4928,
      "step": 4860
    },
    {
      "epoch": 0.7813878860810268,
      "grad_norm": 0.8953500986099243,
      "learning_rate": 4.376704636611584e-05,
      "loss": 1.6192,
      "step": 4870
    },
    {
      "epoch": 0.7829923786602487,
      "grad_norm": 0.6970838308334351,
      "learning_rate": 4.3446173592170705e-05,
      "loss": 1.6412,
      "step": 4880
    },
    {
      "epoch": 0.7845968712394705,
      "grad_norm": 0.6251868605613708,
      "learning_rate": 4.312530081822558e-05,
      "loss": 1.6105,
      "step": 4890
    },
    {
      "epoch": 0.7862013638186923,
      "grad_norm": 0.6295376420021057,
      "learning_rate": 4.280442804428044e-05,
      "loss": 1.4452,
      "step": 4900
    },
    {
      "epoch": 0.7878058563979141,
      "grad_norm": 0.412665992975235,
      "learning_rate": 4.248355527033531e-05,
      "loss": 1.4802,
      "step": 4910
    },
    {
      "epoch": 0.789410348977136,
      "grad_norm": 0.5739436149597168,
      "learning_rate": 4.216268249639018e-05,
      "loss": 1.4319,
      "step": 4920
    },
    {
      "epoch": 0.7910148415563578,
      "grad_norm": 0.6355472207069397,
      "learning_rate": 4.1841809722445054e-05,
      "loss": 1.4836,
      "step": 4930
    },
    {
      "epoch": 0.7926193341355796,
      "grad_norm": 0.7134342193603516,
      "learning_rate": 4.152093694849992e-05,
      "loss": 1.5887,
      "step": 4940
    },
    {
      "epoch": 0.7942238267148014,
      "grad_norm": 0.4467025399208069,
      "learning_rate": 4.1200064174554795e-05,
      "loss": 1.351,
      "step": 4950
    },
    {
      "epoch": 0.7958283192940233,
      "grad_norm": 0.5786726474761963,
      "learning_rate": 4.087919140060966e-05,
      "loss": 1.527,
      "step": 4960
    },
    {
      "epoch": 0.7974328118732451,
      "grad_norm": 0.5278319716453552,
      "learning_rate": 4.055831862666453e-05,
      "loss": 1.6284,
      "step": 4970
    },
    {
      "epoch": 0.7990373044524669,
      "grad_norm": 0.47266122698783875,
      "learning_rate": 4.0237445852719396e-05,
      "loss": 1.4685,
      "step": 4980
    },
    {
      "epoch": 0.8006417970316887,
      "grad_norm": 0.8309816122055054,
      "learning_rate": 3.9916573078774263e-05,
      "loss": 1.5646,
      "step": 4990
    },
    {
      "epoch": 0.8022462896109106,
      "grad_norm": 0.8524652719497681,
      "learning_rate": 3.959570030482914e-05,
      "loss": 1.371,
      "step": 5000
    },
    {
      "epoch": 0.8038507821901324,
      "grad_norm": 0.8723599910736084,
      "learning_rate": 3.9274827530884004e-05,
      "loss": 1.5715,
      "step": 5010
    },
    {
      "epoch": 0.8054552747693542,
      "grad_norm": 0.654076337814331,
      "learning_rate": 3.895395475693888e-05,
      "loss": 1.4282,
      "step": 5020
    },
    {
      "epoch": 0.807059767348576,
      "grad_norm": 0.56080162525177,
      "learning_rate": 3.8633081982993745e-05,
      "loss": 1.3019,
      "step": 5030
    },
    {
      "epoch": 0.8086642599277978,
      "grad_norm": 0.8686108589172363,
      "learning_rate": 3.831220920904862e-05,
      "loss": 1.5774,
      "step": 5040
    },
    {
      "epoch": 0.8102687525070197,
      "grad_norm": 0.629419207572937,
      "learning_rate": 3.799133643510348e-05,
      "loss": 1.6471,
      "step": 5050
    },
    {
      "epoch": 0.8118732450862415,
      "grad_norm": 0.7823655009269714,
      "learning_rate": 3.7670463661158353e-05,
      "loss": 1.5032,
      "step": 5060
    },
    {
      "epoch": 0.8134777376654633,
      "grad_norm": 0.5475064516067505,
      "learning_rate": 3.734959088721322e-05,
      "loss": 1.5124,
      "step": 5070
    },
    {
      "epoch": 0.8150822302446851,
      "grad_norm": 0.7570406198501587,
      "learning_rate": 3.702871811326809e-05,
      "loss": 1.5643,
      "step": 5080
    },
    {
      "epoch": 0.816686722823907,
      "grad_norm": 0.8026365637779236,
      "learning_rate": 3.670784533932296e-05,
      "loss": 1.601,
      "step": 5090
    },
    {
      "epoch": 0.8182912154031288,
      "grad_norm": 0.6398471593856812,
      "learning_rate": 3.638697256537783e-05,
      "loss": 1.5172,
      "step": 5100
    },
    {
      "epoch": 0.8198957079823506,
      "grad_norm": 0.8656153678894043,
      "learning_rate": 3.60660997914327e-05,
      "loss": 1.4717,
      "step": 5110
    },
    {
      "epoch": 0.8215002005615724,
      "grad_norm": 0.8454347848892212,
      "learning_rate": 3.574522701748757e-05,
      "loss": 1.5751,
      "step": 5120
    },
    {
      "epoch": 0.8231046931407943,
      "grad_norm": 0.6655798554420471,
      "learning_rate": 3.542435424354244e-05,
      "loss": 1.665,
      "step": 5130
    },
    {
      "epoch": 0.8247091857200161,
      "grad_norm": 0.9656740427017212,
      "learning_rate": 3.5103481469597304e-05,
      "loss": 1.4368,
      "step": 5140
    },
    {
      "epoch": 0.8263136782992379,
      "grad_norm": 0.9514742493629456,
      "learning_rate": 3.478260869565218e-05,
      "loss": 1.3227,
      "step": 5150
    },
    {
      "epoch": 0.8279181708784596,
      "grad_norm": 0.6327433586120605,
      "learning_rate": 3.4461735921707045e-05,
      "loss": 1.6415,
      "step": 5160
    },
    {
      "epoch": 0.8295226634576816,
      "grad_norm": 0.6520902514457703,
      "learning_rate": 3.414086314776191e-05,
      "loss": 1.5231,
      "step": 5170
    },
    {
      "epoch": 0.8311271560369033,
      "grad_norm": 0.6328153014183044,
      "learning_rate": 3.3819990373816786e-05,
      "loss": 1.6521,
      "step": 5180
    },
    {
      "epoch": 0.8327316486161251,
      "grad_norm": 0.4575961232185364,
      "learning_rate": 3.349911759987165e-05,
      "loss": 1.6271,
      "step": 5190
    },
    {
      "epoch": 0.8343361411953469,
      "grad_norm": 0.6450724005699158,
      "learning_rate": 3.317824482592653e-05,
      "loss": 1.5135,
      "step": 5200
    },
    {
      "epoch": 0.8359406337745688,
      "grad_norm": 0.5678373575210571,
      "learning_rate": 3.285737205198139e-05,
      "loss": 1.5561,
      "step": 5210
    },
    {
      "epoch": 0.8375451263537906,
      "grad_norm": 0.8395776152610779,
      "learning_rate": 3.253649927803626e-05,
      "loss": 1.5136,
      "step": 5220
    },
    {
      "epoch": 0.8391496189330124,
      "grad_norm": 0.6020161509513855,
      "learning_rate": 3.221562650409113e-05,
      "loss": 1.623,
      "step": 5230
    },
    {
      "epoch": 0.8407541115122342,
      "grad_norm": 0.690737247467041,
      "learning_rate": 3.1894753730146e-05,
      "loss": 1.4952,
      "step": 5240
    },
    {
      "epoch": 0.8423586040914561,
      "grad_norm": 0.905783474445343,
      "learning_rate": 3.157388095620087e-05,
      "loss": 1.5095,
      "step": 5250
    },
    {
      "epoch": 0.8439630966706779,
      "grad_norm": 0.6855214834213257,
      "learning_rate": 3.1253008182255736e-05,
      "loss": 1.5991,
      "step": 5260
    },
    {
      "epoch": 0.8455675892498997,
      "grad_norm": 0.8853878974914551,
      "learning_rate": 3.093213540831061e-05,
      "loss": 1.7378,
      "step": 5270
    },
    {
      "epoch": 0.8471720818291215,
      "grad_norm": 0.7459388971328735,
      "learning_rate": 3.061126263436547e-05,
      "loss": 1.6527,
      "step": 5280
    },
    {
      "epoch": 0.8487765744083433,
      "grad_norm": 0.9363895058631897,
      "learning_rate": 3.0290389860420344e-05,
      "loss": 1.5,
      "step": 5290
    },
    {
      "epoch": 0.8503810669875652,
      "grad_norm": 0.7444343566894531,
      "learning_rate": 2.996951708647521e-05,
      "loss": 1.4709,
      "step": 5300
    },
    {
      "epoch": 0.851985559566787,
      "grad_norm": 0.7191593647003174,
      "learning_rate": 2.964864431253008e-05,
      "loss": 1.3961,
      "step": 5310
    },
    {
      "epoch": 0.8535900521460088,
      "grad_norm": 1.1171200275421143,
      "learning_rate": 2.9327771538584952e-05,
      "loss": 1.7303,
      "step": 5320
    },
    {
      "epoch": 0.8551945447252306,
      "grad_norm": 0.8517017960548401,
      "learning_rate": 2.9006898764639823e-05,
      "loss": 1.5858,
      "step": 5330
    },
    {
      "epoch": 0.8567990373044525,
      "grad_norm": 0.9792931079864502,
      "learning_rate": 2.8686025990694693e-05,
      "loss": 1.5837,
      "step": 5340
    },
    {
      "epoch": 0.8584035298836743,
      "grad_norm": 0.6873613595962524,
      "learning_rate": 2.8365153216749564e-05,
      "loss": 1.5785,
      "step": 5350
    },
    {
      "epoch": 0.8600080224628961,
      "grad_norm": 0.8631881475448608,
      "learning_rate": 2.8044280442804427e-05,
      "loss": 1.4928,
      "step": 5360
    },
    {
      "epoch": 0.8616125150421179,
      "grad_norm": 0.6689881086349487,
      "learning_rate": 2.7723407668859298e-05,
      "loss": 1.5605,
      "step": 5370
    },
    {
      "epoch": 0.8632170076213398,
      "grad_norm": 0.6695940494537354,
      "learning_rate": 2.740253489491417e-05,
      "loss": 1.466,
      "step": 5380
    },
    {
      "epoch": 0.8648215002005616,
      "grad_norm": 0.3990181088447571,
      "learning_rate": 2.7081662120969035e-05,
      "loss": 1.6322,
      "step": 5390
    },
    {
      "epoch": 0.8664259927797834,
      "grad_norm": 0.842883825302124,
      "learning_rate": 2.6760789347023906e-05,
      "loss": 1.4816,
      "step": 5400
    },
    {
      "epoch": 0.8680304853590052,
      "grad_norm": 0.6961751580238342,
      "learning_rate": 2.6439916573078776e-05,
      "loss": 1.541,
      "step": 5410
    },
    {
      "epoch": 0.8696349779382271,
      "grad_norm": 0.7823480367660522,
      "learning_rate": 2.6119043799133647e-05,
      "loss": 1.5845,
      "step": 5420
    },
    {
      "epoch": 0.8712394705174489,
      "grad_norm": 0.747918963432312,
      "learning_rate": 2.5798171025188517e-05,
      "loss": 1.5429,
      "step": 5430
    },
    {
      "epoch": 0.8728439630966707,
      "grad_norm": 0.574978232383728,
      "learning_rate": 2.547729825124338e-05,
      "loss": 1.4584,
      "step": 5440
    },
    {
      "epoch": 0.8744484556758925,
      "grad_norm": 0.6774701476097107,
      "learning_rate": 2.515642547729825e-05,
      "loss": 1.5177,
      "step": 5450
    },
    {
      "epoch": 0.8760529482551144,
      "grad_norm": 1.2712023258209229,
      "learning_rate": 2.4835552703353122e-05,
      "loss": 1.5592,
      "step": 5460
    },
    {
      "epoch": 0.8776574408343362,
      "grad_norm": 0.5790585279464722,
      "learning_rate": 2.4514679929407993e-05,
      "loss": 1.5747,
      "step": 5470
    },
    {
      "epoch": 0.879261933413558,
      "grad_norm": 0.8530831933021545,
      "learning_rate": 2.419380715546286e-05,
      "loss": 1.4094,
      "step": 5480
    },
    {
      "epoch": 0.8808664259927798,
      "grad_norm": 0.6290141344070435,
      "learning_rate": 2.3872934381517727e-05,
      "loss": 1.5956,
      "step": 5490
    },
    {
      "epoch": 0.8824709185720016,
      "grad_norm": 0.6144274473190308,
      "learning_rate": 2.3552061607572597e-05,
      "loss": 1.4707,
      "step": 5500
    },
    {
      "epoch": 0.8840754111512235,
      "grad_norm": 0.5356757640838623,
      "learning_rate": 2.3231188833627468e-05,
      "loss": 1.3693,
      "step": 5510
    },
    {
      "epoch": 0.8856799037304453,
      "grad_norm": 0.7995138168334961,
      "learning_rate": 2.2910316059682338e-05,
      "loss": 1.6896,
      "step": 5520
    },
    {
      "epoch": 0.887284396309667,
      "grad_norm": 0.703606903553009,
      "learning_rate": 2.2589443285737205e-05,
      "loss": 1.5133,
      "step": 5530
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.7876867055892944,
      "learning_rate": 2.2268570511792076e-05,
      "loss": 1.5793,
      "step": 5540
    },
    {
      "epoch": 0.8904933814681107,
      "grad_norm": 0.8904472589492798,
      "learning_rate": 2.1947697737846946e-05,
      "loss": 1.3559,
      "step": 5550
    },
    {
      "epoch": 0.8920978740473325,
      "grad_norm": 0.4743182957172394,
      "learning_rate": 2.1626824963901813e-05,
      "loss": 1.4312,
      "step": 5560
    },
    {
      "epoch": 0.8937023666265543,
      "grad_norm": 0.4311690628528595,
      "learning_rate": 2.1305952189956684e-05,
      "loss": 1.2332,
      "step": 5570
    },
    {
      "epoch": 0.8953068592057761,
      "grad_norm": 0.6385003924369812,
      "learning_rate": 2.098507941601155e-05,
      "loss": 1.3648,
      "step": 5580
    },
    {
      "epoch": 0.896911351784998,
      "grad_norm": 0.6424747109413147,
      "learning_rate": 2.066420664206642e-05,
      "loss": 1.4668,
      "step": 5590
    },
    {
      "epoch": 0.8985158443642198,
      "grad_norm": 0.7746299505233765,
      "learning_rate": 2.0343333868121292e-05,
      "loss": 1.4521,
      "step": 5600
    },
    {
      "epoch": 0.9001203369434416,
      "grad_norm": 0.6953763365745544,
      "learning_rate": 2.002246109417616e-05,
      "loss": 1.5359,
      "step": 5610
    },
    {
      "epoch": 0.9017248295226634,
      "grad_norm": 0.5351943969726562,
      "learning_rate": 1.970158832023103e-05,
      "loss": 1.5521,
      "step": 5620
    },
    {
      "epoch": 0.9033293221018853,
      "grad_norm": 0.6754303574562073,
      "learning_rate": 1.93807155462859e-05,
      "loss": 1.5653,
      "step": 5630
    },
    {
      "epoch": 0.9049338146811071,
      "grad_norm": 0.5038592219352722,
      "learning_rate": 1.905984277234077e-05,
      "loss": 1.404,
      "step": 5640
    },
    {
      "epoch": 0.9065383072603289,
      "grad_norm": 0.6110360026359558,
      "learning_rate": 1.8738969998395638e-05,
      "loss": 1.6471,
      "step": 5650
    },
    {
      "epoch": 0.9081427998395507,
      "grad_norm": 0.7876022458076477,
      "learning_rate": 1.8418097224450505e-05,
      "loss": 1.8428,
      "step": 5660
    },
    {
      "epoch": 0.9097472924187726,
      "grad_norm": 0.7446887493133545,
      "learning_rate": 1.8097224450505375e-05,
      "loss": 1.5007,
      "step": 5670
    },
    {
      "epoch": 0.9113517849979944,
      "grad_norm": 0.6651062965393066,
      "learning_rate": 1.7776351676560242e-05,
      "loss": 1.4295,
      "step": 5680
    },
    {
      "epoch": 0.9129562775772162,
      "grad_norm": 0.7486333847045898,
      "learning_rate": 1.7455478902615113e-05,
      "loss": 1.4874,
      "step": 5690
    },
    {
      "epoch": 0.914560770156438,
      "grad_norm": 0.6381528973579407,
      "learning_rate": 1.7134606128669983e-05,
      "loss": 1.6164,
      "step": 5700
    },
    {
      "epoch": 0.9161652627356599,
      "grad_norm": 0.6670570373535156,
      "learning_rate": 1.6813733354724854e-05,
      "loss": 1.4949,
      "step": 5710
    },
    {
      "epoch": 0.9177697553148817,
      "grad_norm": 0.8709273934364319,
      "learning_rate": 1.649286058077972e-05,
      "loss": 1.6298,
      "step": 5720
    },
    {
      "epoch": 0.9193742478941035,
      "grad_norm": 0.6671214699745178,
      "learning_rate": 1.617198780683459e-05,
      "loss": 1.6208,
      "step": 5730
    },
    {
      "epoch": 0.9209787404733253,
      "grad_norm": 0.666677713394165,
      "learning_rate": 1.5851115032889462e-05,
      "loss": 1.4466,
      "step": 5740
    },
    {
      "epoch": 0.9225832330525471,
      "grad_norm": 0.8158405423164368,
      "learning_rate": 1.553024225894433e-05,
      "loss": 1.6211,
      "step": 5750
    },
    {
      "epoch": 0.924187725631769,
      "grad_norm": 0.5491403937339783,
      "learning_rate": 1.5209369484999198e-05,
      "loss": 1.524,
      "step": 5760
    },
    {
      "epoch": 0.9257922182109908,
      "grad_norm": 0.8186943531036377,
      "learning_rate": 1.4888496711054068e-05,
      "loss": 1.5365,
      "step": 5770
    },
    {
      "epoch": 0.9273967107902126,
      "grad_norm": 0.6433718204498291,
      "learning_rate": 1.4567623937108937e-05,
      "loss": 1.5569,
      "step": 5780
    },
    {
      "epoch": 0.9290012033694344,
      "grad_norm": 1.258497953414917,
      "learning_rate": 1.4246751163163807e-05,
      "loss": 1.6294,
      "step": 5790
    },
    {
      "epoch": 0.9306056959486563,
      "grad_norm": 0.7522000074386597,
      "learning_rate": 1.3925878389218674e-05,
      "loss": 1.5901,
      "step": 5800
    },
    {
      "epoch": 0.9322101885278781,
      "grad_norm": 0.7064012885093689,
      "learning_rate": 1.3605005615273545e-05,
      "loss": 1.4447,
      "step": 5810
    },
    {
      "epoch": 0.9338146811070999,
      "grad_norm": 0.7418032884597778,
      "learning_rate": 1.3284132841328414e-05,
      "loss": 1.5142,
      "step": 5820
    },
    {
      "epoch": 0.9354191736863217,
      "grad_norm": 0.7193065881729126,
      "learning_rate": 1.2963260067383284e-05,
      "loss": 1.5039,
      "step": 5830
    },
    {
      "epoch": 0.9370236662655436,
      "grad_norm": 0.5871857404708862,
      "learning_rate": 1.2642387293438151e-05,
      "loss": 1.744,
      "step": 5840
    },
    {
      "epoch": 0.9386281588447654,
      "grad_norm": 0.4278600215911865,
      "learning_rate": 1.2321514519493022e-05,
      "loss": 1.5094,
      "step": 5850
    },
    {
      "epoch": 0.9402326514239872,
      "grad_norm": 0.70607990026474,
      "learning_rate": 1.200064174554789e-05,
      "loss": 1.6963,
      "step": 5860
    },
    {
      "epoch": 0.941837144003209,
      "grad_norm": 0.6582028269767761,
      "learning_rate": 1.167976897160276e-05,
      "loss": 1.3864,
      "step": 5870
    },
    {
      "epoch": 0.9434416365824309,
      "grad_norm": 0.6760823726654053,
      "learning_rate": 1.135889619765763e-05,
      "loss": 1.3883,
      "step": 5880
    },
    {
      "epoch": 0.9450461291616526,
      "grad_norm": 0.5916316509246826,
      "learning_rate": 1.1038023423712499e-05,
      "loss": 1.6485,
      "step": 5890
    },
    {
      "epoch": 0.9466506217408744,
      "grad_norm": 0.7262882590293884,
      "learning_rate": 1.0717150649767367e-05,
      "loss": 1.4488,
      "step": 5900
    },
    {
      "epoch": 0.9482551143200962,
      "grad_norm": 1.0825196504592896,
      "learning_rate": 1.0396277875822236e-05,
      "loss": 1.4076,
      "step": 5910
    },
    {
      "epoch": 0.9498596068993181,
      "grad_norm": 0.5651114583015442,
      "learning_rate": 1.0075405101877105e-05,
      "loss": 1.4154,
      "step": 5920
    },
    {
      "epoch": 0.9514640994785399,
      "grad_norm": 0.7886788249015808,
      "learning_rate": 9.754532327931976e-06,
      "loss": 1.5096,
      "step": 5930
    },
    {
      "epoch": 0.9530685920577617,
      "grad_norm": 0.6223927140235901,
      "learning_rate": 9.433659553986844e-06,
      "loss": 1.3304,
      "step": 5940
    },
    {
      "epoch": 0.9546730846369835,
      "grad_norm": 0.43717795610427856,
      "learning_rate": 9.112786780041715e-06,
      "loss": 1.5021,
      "step": 5950
    },
    {
      "epoch": 0.9562775772162053,
      "grad_norm": 0.5484773516654968,
      "learning_rate": 8.791914006096582e-06,
      "loss": 1.4686,
      "step": 5960
    },
    {
      "epoch": 0.9578820697954272,
      "grad_norm": 1.1152570247650146,
      "learning_rate": 8.471041232151452e-06,
      "loss": 1.6243,
      "step": 5970
    },
    {
      "epoch": 0.959486562374649,
      "grad_norm": 0.7335880398750305,
      "learning_rate": 8.150168458206321e-06,
      "loss": 1.7502,
      "step": 5980
    },
    {
      "epoch": 0.9610910549538708,
      "grad_norm": 0.5465243458747864,
      "learning_rate": 7.829295684261192e-06,
      "loss": 1.5123,
      "step": 5990
    },
    {
      "epoch": 0.9626955475330926,
      "grad_norm": 0.8079046010971069,
      "learning_rate": 7.50842291031606e-06,
      "loss": 1.521,
      "step": 6000
    },
    {
      "epoch": 0.9643000401123145,
      "grad_norm": 0.6655935645103455,
      "learning_rate": 7.187550136370929e-06,
      "loss": 1.2083,
      "step": 6010
    },
    {
      "epoch": 0.9659045326915363,
      "grad_norm": 0.750331461429596,
      "learning_rate": 6.866677362425798e-06,
      "loss": 1.512,
      "step": 6020
    },
    {
      "epoch": 0.9675090252707581,
      "grad_norm": 0.8711615800857544,
      "learning_rate": 6.5458045884806685e-06,
      "loss": 1.6049,
      "step": 6030
    },
    {
      "epoch": 0.9691135178499799,
      "grad_norm": 0.4264550507068634,
      "learning_rate": 6.2249318145355365e-06,
      "loss": 1.5084,
      "step": 6040
    },
    {
      "epoch": 0.9707180104292018,
      "grad_norm": 1.0431636571884155,
      "learning_rate": 5.904059040590406e-06,
      "loss": 1.4266,
      "step": 6050
    },
    {
      "epoch": 0.9723225030084236,
      "grad_norm": 0.5515322685241699,
      "learning_rate": 5.583186266645275e-06,
      "loss": 1.4701,
      "step": 6060
    },
    {
      "epoch": 0.9739269955876454,
      "grad_norm": 0.7322913408279419,
      "learning_rate": 5.2623134927001445e-06,
      "loss": 1.5503,
      "step": 6070
    },
    {
      "epoch": 0.9755314881668672,
      "grad_norm": 0.5642201900482178,
      "learning_rate": 4.941440718755014e-06,
      "loss": 1.5875,
      "step": 6080
    },
    {
      "epoch": 0.9771359807460891,
      "grad_norm": 0.6754730343818665,
      "learning_rate": 4.620567944809883e-06,
      "loss": 1.5082,
      "step": 6090
    },
    {
      "epoch": 0.9787404733253109,
      "grad_norm": 0.7252540588378906,
      "learning_rate": 4.299695170864753e-06,
      "loss": 1.7405,
      "step": 6100
    },
    {
      "epoch": 0.9803449659045327,
      "grad_norm": 0.6803169846534729,
      "learning_rate": 3.978822396919621e-06,
      "loss": 1.646,
      "step": 6110
    },
    {
      "epoch": 0.9819494584837545,
      "grad_norm": 0.7154663801193237,
      "learning_rate": 3.657949622974491e-06,
      "loss": 1.6591,
      "step": 6120
    },
    {
      "epoch": 0.9835539510629764,
      "grad_norm": 0.46506446599960327,
      "learning_rate": 3.3370768490293603e-06,
      "loss": 1.2448,
      "step": 6130
    },
    {
      "epoch": 0.9851584436421982,
      "grad_norm": 0.44782066345214844,
      "learning_rate": 3.0162040750842295e-06,
      "loss": 1.4392,
      "step": 6140
    },
    {
      "epoch": 0.98676293622142,
      "grad_norm": 0.9356756806373596,
      "learning_rate": 2.6953313011390987e-06,
      "loss": 1.4553,
      "step": 6150
    },
    {
      "epoch": 0.9883674288006418,
      "grad_norm": 0.499362975358963,
      "learning_rate": 2.3744585271939675e-06,
      "loss": 1.6256,
      "step": 6160
    },
    {
      "epoch": 0.9899719213798637,
      "grad_norm": 0.5462506413459778,
      "learning_rate": 2.0535857532488367e-06,
      "loss": 1.4788,
      "step": 6170
    },
    {
      "epoch": 0.9915764139590855,
      "grad_norm": 0.6372292637825012,
      "learning_rate": 1.7327129793037061e-06,
      "loss": 1.2817,
      "step": 6180
    },
    {
      "epoch": 0.9931809065383073,
      "grad_norm": 0.5928946733474731,
      "learning_rate": 1.4118402053585753e-06,
      "loss": 1.6829,
      "step": 6190
    },
    {
      "epoch": 0.9947853991175291,
      "grad_norm": 1.014240026473999,
      "learning_rate": 1.0909674314134445e-06,
      "loss": 1.5425,
      "step": 6200
    },
    {
      "epoch": 0.9963898916967509,
      "grad_norm": 0.7092434167861938,
      "learning_rate": 7.700946574683139e-07,
      "loss": 1.4952,
      "step": 6210
    },
    {
      "epoch": 0.9979943842759728,
      "grad_norm": 0.7242686152458191,
      "learning_rate": 4.492218835231831e-07,
      "loss": 1.5253,
      "step": 6220
    },
    {
      "epoch": 0.9995988768551946,
      "grad_norm": 0.4912053942680359,
      "learning_rate": 1.283491095780523e-07,
      "loss": 1.4427,
      "step": 6230
    }
  ],
  "logging_steps": 10,
  "max_steps": 6233,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0253774685667328e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
