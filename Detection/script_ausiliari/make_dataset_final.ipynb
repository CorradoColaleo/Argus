{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA: NON ELIMINARE GLI OUTPUT PER VEDERE I RISULTATI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "CSV_PATH = \"TREC-05.csv\"  # percorso CSV\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "df_trec = pd.read_csv(\n",
    "    CSV_PATH,\n",
    "    engine='python',\n",
    ")\n",
    "\n",
    "CSV_PATH = \"Nazario.csv\"  # percorso CSV\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "df_nazario = pd.read_csv(\n",
    "    CSV_PATH,\n",
    "    engine='python',\n",
    ")\n",
    "\n",
    "CSV_PATH = \"Nigerian_Fraud.csv\"  # percorso CSV\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "df_nigeriane = pd.read_csv(\n",
    "    CSV_PATH,\n",
    "    engine='python',\n",
    ")\n",
    "\n",
    "CSV_PATH = \"TREC-07.csv\"  # percorso CSV\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "df_trec07 = pd.read_csv(\n",
    "    CSV_PATH,\n",
    "    engine='python',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trec07_1 = df_trec07[df_trec07[\"label\"]==1]  #Dopo vari tentativi Ã¨ stata notata l'esigenza di ulteriori entry con\n",
    "                                                #label 1 (Phishing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenazione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_trec, df_nazario, df_nigeriane,df_trec07_1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per visualizzare lo stato del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_metrics(df, name=\"Dataset\", label_col=\"label\"):\n",
    "    print(f\"\\nðŸ“Š Metriche - {name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(f\"Numero righe: {df.shape[0]}\")\n",
    "    print(f\"Numero colonne: {df.shape[1]}\")\n",
    "    \n",
    "    print(\"\\nColonne:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    print(\"\\nValori mancanti per colonna:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Conteggio label 0 e 1\n",
    "    if label_col in df.columns:\n",
    "        print(f\"\\nDistribuzione label ({label_col}):\")\n",
    "        print(df[label_col].value_counts().sort_index())\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Colonna label '{label_col}' non trovata nel DataFrame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_trec07_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_trec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_trec07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_nigeriane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_nazario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisi Indici con valori mancanti sui campi: \"receiver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def trova_missing_df(df, campo):\n",
    "    \"\"\"\n",
    "    Restituisce le righe di un DataFrame in cui il campo specificato Ã¨ mancante (NaN o None)\n",
    "    \"\"\"\n",
    "    # Seleziona le righe dove il campo Ã¨ NaN o None\n",
    "    missing_rows = df[df[campo].isna()]\n",
    "    return missing_rows\n",
    "\n",
    "# Esempio di utilizzo\n",
    "campo_da_controllare = \"receiver\"\n",
    "mancanti = trova_missing_df(df, campo_da_controllare)\n",
    "\n",
    "print(f\"Istanze con '{campo_da_controllare}' mancante:\")\n",
    "print(mancanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[176]        #visualizzo un istanza mancante per vedere se veramente manca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminazione delle righe con un campo mancante (\"sender\", \"receiver\", \"urls\", \"label\", \"date\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_with_nan_in_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Rimuove le righe che hanno NaN in una qualunque delle colonne specificate.\n",
    "    \"\"\"\n",
    "    cols = [c for c in columns if c in df.columns]\n",
    "\n",
    "    print(f\"Colonne controllate: {cols}\")\n",
    "\n",
    "    initial_rows = len(df)\n",
    "    df_clean = df.dropna(subset=cols)           #eliminazione NaN\n",
    "    removed_rows = initial_rows - len(df_clean)\n",
    "\n",
    "    print(f\"Righe rimosse: {removed_rows}\")\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "cols_to_drop = [\"sender\",\"receiver\",\"date\",\"label\",\"urls\"]  #campi da controllare -> mancano subject e body perchÃ¨ sono casi interessanti per la detection\n",
    "\n",
    "df = drop_rows_with_nan_in_columns(df,cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df)         #verifico che solo body e subject possono avere valori non NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulizia Caratteri Strani e Punteggiatura\n",
    "\n",
    "Funzione che restituisce True se vi sono troppi caratteri strani nel testo, o troppa punteggiatura. \n",
    "\n",
    "La rimozione avviene verificando una percentuale, al superamento di una soglia deve indicare la volontÃ  di eliminare la riga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "def is_standard_char(c):\n",
    "    \"\"\"\n",
    "    Restituisce True se il carattere Ã¨ 'standard' (lettere e numeri ASCII)\n",
    "    \"\"\"\n",
    "    return c in string.ascii_letters + string.digits + ' '\n",
    "\n",
    "def is_punctuation(c):\n",
    "    \"\"\"\n",
    "    Restituisce True se il carattere Ã¨ punteggiatura comune\n",
    "    \"\"\"\n",
    "    return c in string.punctuation\n",
    "\n",
    "def is_weird_char(c):\n",
    "    \"\"\"\n",
    "    Restituisce True se il carattere Ã¨ 'strano', cioÃ¨ non standard e non punteggiatura\n",
    "    \"\"\"\n",
    "    return not is_standard_char(c) and not is_punctuation(c)\n",
    "\n",
    "def should_discard(text, weird_threshold=0.5, punctuation_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Decide se scartare un testo basandosi sulla percentuale di caratteri strani o punteggiatura\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "\n",
    "    if not text.strip():  # se il testo Ã¨ vuoto o solo spazi\n",
    "        return False\n",
    "\n",
    "    total_chars = len(text)\n",
    "    if total_chars == 0:\n",
    "        return False\n",
    "\n",
    "    weird_count = sum(1 for c in text if is_weird_char(c))          #Somma dei caratteri strani\n",
    "    punctuation_count = sum(1 for c in text if is_punctuation(c))   #Somma dei caratteri usati come punteggiatura\n",
    "\n",
    "    weird_ratio = weird_count / total_chars                         #Percentuale di caratteri strani sul corpo totale\n",
    "    punctuation_ratio = punctuation_count / total_chars             #Percentuale di caratteri usati come punteggiatura sul corpo totale\n",
    "\n",
    "    # scarta se supera le soglie\n",
    "    if weird_ratio > weird_threshold:\n",
    "        return True\n",
    "    if punctuation_ratio > punctuation_threshold:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_dataset(df,  text_column = \"body\", weird_threshold=0.4, punctuation_threshold=0.5):\n",
    "\n",
    "    # Applicare il filtro\n",
    "    discard_mask = df[text_column].apply(\n",
    "        lambda x: should_discard(x, weird_threshold, punctuation_threshold)     #Verifica gli indici da eliminare\n",
    "    )\n",
    "    discarded_count = discard_mask.sum()                                        #somma delle entry eliminate\n",
    "\n",
    "        # Indici dei testi scartati\n",
    "    discarded_indices = df.index[discard_mask].tolist()                         #lista degli indici eliminati\n",
    "\n",
    "    df_clean = df[~discard_mask].copy().reset_index(drop=True)                  #Eliminazione\n",
    "    return df_clean, discarded_count, discarded_indices         #returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df                                           #Usato successivamente per debugging\n",
    "dataset_metrics(df)\n",
    "df, count, lista_strani = clean_text_dataset(df)        #pulizia di df\n",
    "print(count)                                            #Print del numero di entry eliminate\n",
    "dataset_metrics(df)                                     #Stampa, utile per vedere il numero attuale di entry nel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stampa_body(dataset):\n",
    "    \"\"\"\n",
    "    Itera su tutte le righe di un DataFrame e stampa solo il campo 'body'.\n",
    "    \"\"\"\n",
    "    for index, row in dataset.iterrows():\n",
    "        print(f\"Riga {index}: {row['body']}\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_check.loc[lista_strani].copy().reset_index(drop=True)       #df_cleaned contiene solo le entry eliminate\n",
    "dataset_metrics(df_cleaned) #Controllo il numero di entry eliminate (deve coincidere con il count restituito precedentemente)\n",
    "stampa_body(df_cleaned)     #Controllo delle entry eliminate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulizia dimensione del dataset (TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(metadata_list, body):          #Unisce le informazioni relative a \"sender\" \"receiver\" \"date\" \"subject\"\n",
    "                                                #al body. Per distinguere i campi sono stati usati dei separatori | .\n",
    "                                                #Infine si aggiunge anche l'istruzione usata per la fase di detection.\n",
    "                                                #build_prompt restituisce in uscita la struttura del prompt usato anche\n",
    "                                                #in fase di detection.\n",
    "\n",
    "    #Formattazione delle informazioni aggiuntive\n",
    "    #FIELDS = ['sender', 'receiver', 'date', 'subject']\n",
    "    metadata_prompt = (\n",
    "        \"sender: \" + str(metadata_list[0]) + \" | \" +\n",
    "        \"receiver: \" + str(metadata_list[1]) + \" | \" +\n",
    "        \"date: \" + str(metadata_list[2]) + \" | \" +\n",
    "        \"subject: \" + str(metadata_list[3])\n",
    "    )\n",
    "    \n",
    "    #Aggiungo il body\n",
    "    body_text = metadata_prompt + \" | body: \" + body\n",
    "\n",
    "    #Aggiungo l'istruzione\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "You are a classification model specializing in emails, and your job is to detect phishing: respond only with \\\"0\\\" if it is not phishing or \\\"1\\\" if it is phishing, without explanations, symbols, additional letters, or other characters.\n",
    "### Input:\n",
    "{body_text}\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_max_token(df):\n",
    "\n",
    "\n",
    "    #Caricamento del tokenizer, per poter trasformare il corpo del messaggio di ogni entry in token\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    LORA_ADAPTER_PATH = \"./llama-finetuned-final\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LORA_ADAPTER_PATH)    #caricamento del tokenizer\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    MAX_TOKENS = 1024           #NUMERO MASSIMO DI TOKEN\n",
    "\n",
    "    #Lista delle istanze valide\n",
    "    filtered_dataset = []   \n",
    "\n",
    "    #Lista delle istanze non valide (il cui prompt generato supera i 1024 token)    \n",
    "    overflow_instances = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        #Lista avente le informazioni aggiuntive da inserire nel body, in un ordine prestabilito\n",
    "        metadata_list = [\n",
    "            row[\"sender\"],\n",
    "            row[\"receiver\"],\n",
    "            row[\"date\"],\n",
    "            row[\"subject\"]\n",
    "        ]\n",
    "\n",
    "        #Verifico che subject sia NaN.\n",
    "        if pd.isna(row[\"subject\"]):\n",
    "            metadata_list[3]=\"\"     #Sostituzione NaN con carattere vuoto\n",
    "\n",
    "        body = row[\"body\"]          \n",
    "\n",
    "        #Verifico che body sia NaN\n",
    "        if pd.isna(body):\n",
    "            body=\"\"                 #Sostituzione NaN con un body vuoto    \n",
    "\n",
    "        prompt = build_prompt(metadata_list, body)  #Costruzione prompt\n",
    "\n",
    "        #Trasformazione in token\n",
    "        tokens = tokenizer(\n",
    "            prompt,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=False\n",
    "        )\n",
    "\n",
    "        num_tokens = tokens[\"input_ids\"].shape[1]   \n",
    "\n",
    "        #Smistamento delle righe nelle rispettive liste\n",
    "        if num_tokens <= MAX_TOKENS:\n",
    "            filtered_dataset.append(row)\n",
    "        else:\n",
    "            overflow_instances.append(row)\n",
    "\n",
    "        # Stampa progresso ogni 5000 iterazioni\n",
    "        if (idx + 1) % 5000 == 0:\n",
    "            print(f\"Elaborate {idx + 1} righe su {len(df)}...\")\n",
    "\n",
    "    print(f\"Istanze totali: {len(df)}\")\n",
    "    print(f\"Istanze valide (<=1024): {len(filtered_dataset)}\")\n",
    "    print(f\"Istanze scartate: {len(overflow_instances)}\")\n",
    "\n",
    "    #Restituisco le liste trasformate in Dataset\n",
    "    return pd.DataFrame(filtered_dataset).reset_index(drop=True), pd.DataFrame(overflow_instances).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_sporco = clean_max_token(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_sporco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrittura in un File per visualizzare le righe eliminate a causa della lunghezza eccessiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(0, 8):\n",
    "        f.write(f\"Riga: {i}\\n\")\n",
    "        f.write(df_sporco.iloc[i][\"body\"] + \"\\n\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installazione di sklearn (Da eseguire almeno la prima volta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- FUNZIONE DI PULIZIA ---\n",
    "def rimuovi_duplicati_smart(df,SOGLIA_SIMILARITA):\n",
    "\n",
    "    initial_len = len(df)\n",
    "\n",
    "    # --- FASE 1: DUPLICATI ESATTI (100%) ---\n",
    "    # Identifichiamo quali sono i duplicati PRIMA di cancellarli per poterli stampare\n",
    "    #ComplessitÃ  O(n) per fare un filtraggio iniziale\n",
    "\n",
    "    mask_duplicati_esatti = df.duplicated(subset='body', keep='first')\n",
    "    df_esatti_eliminati = df[mask_duplicati_esatti].copy()\n",
    "    \n",
    "    num_esatti = len(df_esatti_eliminati)\n",
    "    print(f\"   -> Trovati {num_esatti} duplicati ESATTI (100%).\")\n",
    "\n",
    "    # STAMPA ESATTI (Max 50)\n",
    "    if num_esatti > 0:\n",
    "        print(f\"   ðŸ”» ESEMPI RIMOSSI (Esatti) - Mostro i primi {min(50, num_esatti)}:\")\n",
    "        for i, text in enumerate(df_esatti_eliminati['body'].head(50)):\n",
    "            text_str = str(text).replace('\\n', ' ')\n",
    "            print(f\"      [X] {text_str[:100]}...\") # Stampa i primi 100 caratteri\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "\n",
    "    # Rimozione effettiva Esatti\n",
    "    df = df[~mask_duplicati_esatti].reset_index(drop=True)\n",
    "    len_after_exact = len(df)\n",
    "\n",
    "    # Se il dataset Ã¨ diventato troppo piccolo, ci fermiamo in quanto non Ã¨ possibile eseguire la funzione su meno di 2 righe\n",
    "    if len_after_exact < 2:\n",
    "        return df\n",
    "\n",
    "    # --- FASE 2: QUASI DUPLICATI (80%) ---\n",
    "    #ComplessitÃ  di O(n^2) su un numero di campioni ridotti grazie al filtraggio di quelli identici\n",
    "    print(\"   -> Calcolo similaritÃ  (quasi-duplicati)...\")\n",
    "    \n",
    "    corpus = df['body'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', min_df=1)        \n",
    "\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)  \n",
    "\n",
    "    cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)       #Applicazione della cosine similarity\n",
    "    upper_tri = np.triu(cosine_sim_matrix, k=1)             #Eliminazione dei controlli duplicati\n",
    "    \n",
    "    to_drop = set()                                         #to_drop indica le entry da eliminare\n",
    "    rows, cols = np.where(upper_tri > SOGLIA_SIMILARITA)    #Colonne che superano la similaritÃ  soglia\n",
    "\n",
    "    #Aggiunta delle entry da eliminare\n",
    "    for r, c in zip(rows, cols):\n",
    "        if r not in to_drop:\n",
    "            to_drop.add(c)\n",
    "            \n",
    "            #Stampa delle entry che hanno fornito una similaritÃ  maggiore della soglia\n",
    "            print(f\"      [~] Indici ({r}, {c}) - SimilaritÃ : {cosine_sim_matrix[r,c]:.2f}\")\n",
    "            print(f\"         -> {df.iloc[r]['body'][:100]}...\")         \n",
    "            print(f\"         -> {df.iloc[c]['body'][:100]}...\\n\")\n",
    "\n",
    "    num_quasi = len(to_drop)        #Numero di entry da eliminare che superano la soglia fissata\n",
    "    \n",
    "    # STAMPA QUASI DUPLICATI (Max 50)\n",
    "    if num_quasi > 0:\n",
    "        '''\n",
    "        print(f\"   -> Trovati {num_quasi} messaggi QUASI identici (>80%).\")\n",
    "        print(f\"   ðŸ”» ESEMPI RIMOSSI (Simili) - Mostro i primi {min(50, num_quasi)}:\")\n",
    "        \n",
    "        # Recuperiamo le righe da eliminare usando gli indici\n",
    "        df_quasi_eliminati = df.iloc[list(to_drop)]\n",
    "        \n",
    "        for i, text in enumerate(df_quasi_eliminati['body'].head(50)):\n",
    "            text_str = str(text).replace('\\n', ' ')\n",
    "            #print(f\"      [~] {text_str[:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "        '''\n",
    "        # Rimozione effettiva dei Quasi Duplicati\n",
    "        df_clean = df.drop(index=list(to_drop)).reset_index(drop=True)\n",
    "    else:\n",
    "        print(\"   -> Nessun quasi duplicato trovato.\")\n",
    "        df_clean = df.reset_index(drop=True)\n",
    "\n",
    "    totale_rimossi = initial_len - len(df_clean)\n",
    "    print(f\"   Dataset Finale: {len(df_clean)} campioni (Totale rimossi: {totale_rimossi})\")\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stampa sul file csv per poter controllare manualmente i duplicati\n",
    "df.to_csv(\"df.csv\", sep=\",\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df)\n",
    "\n",
    "df = rimuovi_duplicati_smart(df,0.75)           #Eliminazione delle righe simili con una soglia di 0.75\n",
    "\n",
    "dataset_metrics(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memorizzazione del Dataset dopo la pulizia (Opzionale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"dopo_duplicati.json\", orient=\"records\", force_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento del Dataset dopo la pulizia dei duplicati (Opzionale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "df = pd.read_json(\"dopo_duplicati.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installazione libreria per se i testi sono costituiti da parole reali nel dizionario inglese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordfreq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "\n",
    "def english_word_ratio(text, threshold=2.5):\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return 0        #se il testo Ã¨ NaN \n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return 0        #se il testo Ã¨ vuoto\n",
    "\n",
    "    valid = [w for w in words if zipf_frequency(w, \"en\") > threshold]   #Ogni parola Ã¨ associata a un valore strettamente\n",
    "                                                                        #positivo (>=0). Una parola rara ma reale assume\n",
    "                                                                        #valori maggiori di 2 (>=2). Parole non inglesi assumono\n",
    "                                                                        #Valori fra 0 e 2 (0 <= x <= 2). Tanto piÃ¹ le parole\n",
    "                                                                        #sono comuni maggiore sarÃ  il valore ad esse \n",
    "                                                                        #associato.\n",
    "                                                                        #threshold indica che vogliamo eliminare solo le \n",
    "                                                                        #parole con valore minore di 2.5\n",
    "    \n",
    "    #Rapporto tra parole valide e parole totali\n",
    "    return len(valid) / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entries_above_ratio(df, ratio_threshold, text_column=\"body\" , wordfreq_threshold=2.5):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for text in df[text_column]:\n",
    "\n",
    "        #Ratio del testo considerato\n",
    "        ratio = english_word_ratio(text, threshold=wordfreq_threshold)  \n",
    "\n",
    "        if ratio > ratio_threshold:\n",
    "            count += 1      #Conteggio delle entry valide\n",
    "\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(count_entries_above_ratio(df,0.8))    #I testi validi ammontano a 42624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_entries_by_ratio(df, ratio_threshold, text_column=\"body\", wordfreq_threshold=2.5):\n",
    "    # Calcolo il ratio per ogni riga\n",
    "    ratios = df[text_column].apply(lambda x: english_word_ratio(x, threshold=wordfreq_threshold))\n",
    "\n",
    "    # Filtra il DataFrame usando la soglia\n",
    "    df_dest = df[ratios > ratio_threshold].copy()\n",
    "    \n",
    "    #Dataset sorgente filtrato\n",
    "    return df_dest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prova = filter_entries_by_ratio(df,0.8)\n",
    "dataset_metrics(df_prova)   #Controllo per verificare che il numero di righe coincida con 42624 righe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINE PULIZIA DATASET COMPLESSIVO.\n",
    "Split in 2 dataset -> Email Normali -> Email di Phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[df[\"label\"] == 0]  #df0 -> DataFrame NON di Phishing\n",
    "df1 = df[df[\"label\"] == 1]  #df1 -> DataFrame di Phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifica delle email di risposta\n",
    "\n",
    "Questa funzione permette di verificare quante email contengono il prefisso **\"Original Message\"**.\n",
    "\n",
    "Il prefisso *\"Original Message\"* Ã¨ tipicamente presente nelle email che rispondono ad altri messaggi; la sua individuazione consente quindi di confermare con certezza la presenza di email di risposta allâ€™interno del dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_original_message(text, pattern=\"Original Message\"):\n",
    "    \"\"\"\n",
    "    Restituisce True se il testo contiene 'Original Message' (case-insensitive)\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return False\n",
    "\n",
    "    return pattern.lower() in str(text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pattern(df, body_col=\"body\", pattern=\"Original Message\"):\n",
    "    \"\"\"\n",
    "    Stampa il numero di righe in cui il campo body contiene 'Original Message'\n",
    "    \"\"\"\n",
    "    if body_col not in df.columns:\n",
    "        print(f\"âš ï¸ Colonna '{body_col}' non trovata nel DataFrame\")\n",
    "        return 0\n",
    "\n",
    "    #Restituzione di una maschera che indica quali righe presentano \"Original Message\"\n",
    "    mask = df[body_col].astype(str).str.contains(pattern, case=False, na=False)\n",
    "    count = mask.sum()\n",
    "\n",
    "    print(f\"Istanze con '{pattern}' nel {body_col}: {count}\")\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifica delle email che presentano dei file al loro interno.\n",
    "\n",
    "Questa funzione verifica che i file trovati non siano interni a dei link. In entrambi i casi sono stati usati dei regex per l'individuazione di entrambi, per poi verificare che la posizione dei file non coincidesse con quella dei link. \n",
    "\n",
    "I file sono trovati tramite l'utilizzo di un estensione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def contiene_file_non_link(testo: str) -> bool:\n",
    "\n",
    "    #Estensioni famose\n",
    "    FILE_EXTENSIONS = [\n",
    "    # Documenti\n",
    "    \"pdf\", \"doc\", \"docx\", \"csv\", \"xls\", \"xlsx\",\n",
    "    \"txt\", \"ppt\", \"pptx\", \"odt\", \"ods\", \"odp\", \"rtf\",\n",
    "    \n",
    "    # Archivi compressi\n",
    "    \"zip\", \"rar\", \"7z\", \"tar\", \"gz\", \"bz2\",\n",
    "    \n",
    "    # Immagini\n",
    "    \"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\", \"tiff\", \"svg\", \"webp\",\n",
    "    \n",
    "    # Audio\n",
    "    \"mp3\", \"wav\", \"ogg\", \"flac\", \"aac\", \"m4a\",\n",
    "    \n",
    "    # Video\n",
    "    \"mp4\", \"avi\", \"mov\", \"mkv\", \"flv\", \"wmv\", \"webm\"\n",
    "]\n",
    "\n",
    "    if not testo:\n",
    "        return False    #Verifica che il testo non sia vuoto\n",
    "\n",
    "    if testo is None or pd.isna(testo):\n",
    "        return False    #Verifica che il testo non sia NaN\n",
    "\n",
    "    testo_lower = testo.lower()\n",
    "\n",
    "    #All'interno del dataset dei link risultavano separati da degli spazi, tramite le prossime righe di codice\n",
    "    #li uniamo per fornirgli una forma corretta.\n",
    "        # Esempio: \"h t t p : / / example.com\" -> \"http://example.com\"\n",
    "    testo_lower = re.sub(r\"h\\s*t\\s*t\\s*p\\s*s?\\s*:\", \"http:\", testo_lower)\n",
    "    testo_lower = re.sub(r\"w\\s*w\\s*w\\s*\\.\", \"www.\", testo_lower)\n",
    "\n",
    "    # Trova tutti i link\n",
    "    link_regex = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    \n",
    "    #Ottenimento della posizione dei link nel testo fornito\n",
    "    link_spans = [m.span() for m in link_regex.finditer(testo_lower)]\n",
    "\n",
    "    # Trova tutte le estensioni di file\n",
    "    file_regex = re.compile(\n",
    "        rf\"\\b\\S+\\.({'|'.join(FILE_EXTENSIONS)})\\b\"\n",
    "    )\n",
    "\n",
    "    #Si itera per ogni file trovato nel testo\n",
    "    for file_match in file_regex.finditer(testo_lower):\n",
    "        \n",
    "        #si separa l'inizio e la fine del file\n",
    "        file_start, file_end = file_match.span()\n",
    "\n",
    "        #Verifica se il file cade dentro un link, iterando fra tutti i link trovati\n",
    "        is_inside_link = any(\n",
    "            link_start <= file_start and file_end <= link_end\n",
    "            for link_start, link_end in link_spans\n",
    "        )\n",
    "\n",
    "        #Se NON Ã¨ dentro un link â†’ file valido\n",
    "        if not is_inside_link:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conteggio delle entry con un file nel corpo del messaggio\n",
    "def conta_file(df,col_name=\"body\"):\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        testo = df.iloc[i][col_name]\n",
    "        \n",
    "        if contiene_file_non_link(testo):\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifica delle email con numeri di telefono, email o riferimenti di contatto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def has_phone_contact(text):\n",
    "    if pd.isna(text): \n",
    "        return False\n",
    "    \n",
    "    # Convertiamo in stringa e minuscolo\n",
    "    text_str = str(text).lower()\n",
    "    \n",
    "    #Analizzando il codice sono state notate delle forme diverse per indicare il numero di telefono\n",
    "    #Dopo un analizzazione del dataset sono state notate le seguenti forme\n",
    "    patterns_list = [\n",
    "        # --- PATTERN ORIGINALI ---\n",
    "        r\"\\b\\d{3}-\\d{3}-\\d{3}\\b\",           # xxx-xxx-xxx (9 cifre)\n",
    "        r\"\\b\\d{3}-\\d{3}-\\d{4}\\b\",           # xxx-xxx-xxxx (Standard trattini)\n",
    "        r\"\\b\\d{3}\\s\\d{3}\\s\\d{4}\\b\",         # xxx xxx xxxx (Spazi)\n",
    "        r\"\\b\\d-\\d{3}-\\d{3}-\\d{4}\\b\",        # x-xxx-xxx-xxxx (International)\n",
    "        r\"\\b\\d\\.\\d{3}\\.\\d{3}\\.\\d{4}\\b\",     # x.xxx.xxx.xxxx (11 cifre punti)\n",
    "        \n",
    "        r\"\\b\\d{10}\\b\",                      # 1) xxxxxxxxxx (10 cifre unite, senza spazi)\n",
    "        r\"\\(\\d{3}\\)\\s\\d{3}-\\d{4}\\b\",        # 2) (xxx) xxx-xxxx (Parentesi e spazio)\n",
    "        r\"\\b\\d{3}\\s\\d{3}-\\d{4}\\b\",          # 3) xxx xxx-xxxx (Spazio misto trattino)\n",
    "        r\"\\b\\d{3}/\\d{3}-\\d{4}\\b\",           # 4) xxx/xxx-xxxx (Slash misto trattino)\n",
    "        r\"\\b\\d{3}\\.\\d{3}\\.\\d{4}\\b\",         # 5) xxx.xxx.xxxx (10 cifre con punti)\n",
    "        r\"\\(\\d{3}\\)\\d{3}-\\d{4}\\b\"           # 6) (xxx)xxx-xxxx (Parentesi senza spazio)\n",
    "    ]\n",
    "    \n",
    "    # Uniamo tutti i pattern con l'operatore OR \"|\"\n",
    "    combined_phone_regex = \"|\".join(patterns_list)\n",
    "    \n",
    "    #Per rendersi conto dei numeri di telefono sono state usate anche delle parole di riferimento.\n",
    "    #Analizzando il corpo del dataset sono state notate una serie di parole chiave.\n",
    "    keywords = [\n",
    "        \n",
    "        \"phone\", \"cell\", \"tel\", \"mobile\", \"call\", \"fax\", \"ph\", \"mob\", \"Telephone\",\n",
    "        \"hotline\", \"helpline\", \"toll free\", \"toll-free\", \"dial\", \"direct line\",\n",
    "        \"sms\", \"text message\", \"whatsapp\"\n",
    "    ]\n",
    "    \n",
    "    # Creiamo Regex per parole intere\n",
    "    pattern_keywords = r\"\\b(\" + \"|\".join(keywords) + r\")\\b\"\n",
    "    \n",
    "    # --- CONTROLLO FINALE ---\n",
    "    # Cerca se esiste ALMENO uno dei formati numerici\n",
    "    found_strict = bool(re.search(combined_phone_regex, text_str))\n",
    "    \n",
    "    # Cerca se esiste ALMENO una keyword\n",
    "    found_keyword = bool(re.search(pattern_keywords, text_str, flags=re.IGNORECASE))\n",
    "    \n",
    "    return found_strict or found_keyword        #se trova una keyword o almeno un numero di telefono restituisce True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_email_contact(text):\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "\n",
    "    text_str = str(text).lower()\n",
    "\n",
    "    regex_email = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'     #formato email\n",
    "    emails_found = re.findall(regex_email, text_str, flags=re.IGNORECASE)   #Ricerca di email nel body\n",
    "\n",
    "    return len(emails_found) > 0    #Se nel corpo vi Ã¨ almeno una email trovata restituisce True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def check_information_content(text):\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    text_str = str(text)\n",
    "    \n",
    "    # Controllo Telefono\n",
    "    has_phone = has_phone_contact(text_str)\n",
    "        \n",
    "    # Controllo Email\n",
    "    has_email = has_email_contact(text_str)\n",
    "    \n",
    "    # In modo analogo con quanto visto con il controllo dei numeri di telefono, anche in questo caso usiamo delle\n",
    "    #parole chiave.\n",
    "    general_contact_keywords = [\n",
    "\n",
    "        \"contact us\", \"contact me\", \"contact our\",         \n",
    "        \"call us\", \"call me\", \"call our\",                   \n",
    "        \"email us\", \"email me\", \"write to\", \"write us\",     \n",
    "        \"reply to\", \"reply via\", \"respond to\",           \n",
    "        \"reach us at\", \"reach me at\",                      \n",
    "        \"get in touch\", \"feel free to call\",                \n",
    "        \n",
    "        \"private email\", \"personal email\", \"direct email\",  \n",
    "        \"private number\", \"private line\", \"direct line\",    \n",
    "        \"confidential email\", \"confidential number\",       \n",
    "        \"contact the bank\", \"contact the barrister\",        \n",
    "        \"contact the secretary\", \"contact the agent\",       \n",
    "        \"send a fax\", \"send an email\",                      \n",
    "        \"get back to me\", \"return this email\",              \n",
    "        \n",
    "        \"contact support\", \"contact security\",              \n",
    "        \"call customer service\", \"call support\",            \n",
    "        \"contact the resolution center\",                   \n",
    "        \"verify by phone\", \"verify by email\",               \n",
    "        \"fax verification\",                                \n",
    "        \"assistance line\", \"help line\",                     \n",
    "       \n",
    "        \"call now\", \"call for details\",                     \n",
    "        \"order by phone\", \"order via email\",               \n",
    "        \"unsubscribe via email\", \"remove via email\",       \n",
    "        \"call to remove\", \"reply to unsubscribe\",           \n",
    "        \"questions? call\", \"questions? email\"               \n",
    "    ]\n",
    "    \n",
    "    # Creiamo il pattern per cercare le frasi intere\n",
    "    pattern_general = r\"\\b(\" + \"|\".join(general_contact_keywords) + r\")\\b\"\n",
    "    \n",
    "    # Verifichiamo se c'Ã¨ la keyword\n",
    "    has_general_kw = bool(re.search(pattern_general, text_str, flags=re.IGNORECASE))\n",
    "    \n",
    "\n",
    "    # (Ha il telefono E la keyword) OPPURE (Ha la keyword E l'email)\n",
    "    # Normalmente una mail nel caso in cui fornisce delle opzioni di contatto Ã¨ strutturata in modo da avere\n",
    "    # almeno un numero di telefono o un email e delle richieste di contatto che vengono identificate tramite\n",
    "    # parole chiave, ad esempio \"contact us\" o \"email us\"\n",
    "    return (has_phone and has_general_kw) or (has_general_kw and has_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funzione per il conteggio di 3 casi separati\n",
    "# -> Solo delle mail sono presenti nel corpo\n",
    "# -> Solo dei numeri di telefono sono presenti nel corpo\n",
    "# -> Vi Ã¨ la presenza di opzioni di contatto\n",
    "def analizza_dataset(df,col_name=\"body\"):\n",
    "   \n",
    "    count_only_email = 0    # Ha l'email MA NON il telefono\n",
    "    count_only_phone = 0    # Ha il telefono MA NON l'email\n",
    "    count_both = 0          # Ha ENTRAMBI\n",
    "    \n",
    "    total_samples = len(df)\n",
    "\n",
    "    for text in df[col_name]:\n",
    "\n",
    "        if pd.isna(text):\n",
    "            continue\n",
    "            \n",
    "        text_str = str(text).lower()\n",
    "\n",
    "        found_phone = has_phone_contact(text_str)\n",
    "\n",
    "        found_email = has_email_contact(text_str)\n",
    "\n",
    "        if check_information_content(text_str):     #Se vi sono opzioni di contatto\n",
    "            count_both += 1\n",
    "        elif found_phone and not found_email:       #Se vi sono solo numeri di telefono\n",
    "            count_only_phone += 1\n",
    "        elif found_email and not found_phone:       #Se vi sono email\n",
    "            count_only_email += 1\n",
    "\n",
    "    # --- STAMPA RISULTATI ---\n",
    "    print(f\"Totale campioni: {total_samples}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"1. SOLO Email (no telefono): {count_only_email}\")\n",
    "    print(f\"2. SOLO Telefono (no email): {count_only_phone}\")\n",
    "    print(f\"3. Opzioni di Contatto (Email o Telefono): {count_both}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Istogramma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def istogramma(df, n_bins,col_name = \"body\"):\n",
    "\n",
    "    # lunghezze del testo\n",
    "    lengths = df[col_name].astype(str).apply(len)\n",
    "\n",
    "    min_len = lengths.min() \n",
    "    max_len = lengths.max()\n",
    "\n",
    "    #Casi limite\n",
    "    if min_len == max_len:\n",
    "        print(\"Tutti i testi hanno la stessa lunghezza:\", min_len)\n",
    "        return\n",
    "\n",
    "    #Dimensione dei bucket automatica\n",
    "    bin_size = math.ceil((max_len - min_len + 1) / n_bins)\n",
    "\n",
    "    # assegnazione ai bucket\n",
    "    bins = ((lengths - min_len) // bin_size) * bin_size + min_len\n",
    "\n",
    "    # conteggio\n",
    "    histogram = Counter(bins)\n",
    "\n",
    "    # stampa dei conteggio per ogni bucket\n",
    "    print(f\"Istogramma lunghezze (caratteri) â€” {n_bins} bucket\\n\")\n",
    "    for b in range(min_len, max_len + 1, bin_size):\n",
    "        count = histogram.get(b, 0)\n",
    "        bar = \"#\"\n",
    "        print(f\"{b:4d}â€“{b+bin_size-1:4d} | {bar} ({count})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione per eliminare i testi troppo lunghi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimina_lunghe(df, max_chars, colonna=\"body\"):\n",
    "\n",
    "    # assicuriamoci che siano stringhe\n",
    "    df[colonna] = df[colonna].astype(str)\n",
    "    \n",
    "    # eliminazione delle righe troppo lunghe\n",
    "    df_filtrato = df[df[colonna].str.len() <= max_chars].copy()\n",
    "    \n",
    "    return df_filtrato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione per analisi del tono e contesto\n",
    "\n",
    "Questa funzione permette di verificare dei pattern comuni nelle mail di phishing, come il cercare di mettere fretta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parole chiave nelle mail di phishing\n",
    "\n",
    "phishing_urgency_keywords = [\n",
    "\n",
    "    \"urgent\",\n",
    "    \"immediately\",\n",
    "    \"as soon as possible\",\n",
    "    \"asap\",\n",
    "    \"now\",\n",
    "    \"today\",\n",
    "    \"within 24 hours\",\n",
    "    \"within 48 hours\",\n",
    "    \"right away\",\n",
    "    \"final notice\",\n",
    "    \"last chance\",\n",
    "    \"time-sensitive\",\n",
    "    \"expires\",\n",
    "    \"deadline\",\n",
    "    \"act fast\",\n",
    "    \"limited time\",\n",
    "\n",
    "    \"suspended\",\n",
    "    \"terminated\",\n",
    "    \"blocked\",\n",
    "    \"disabled\",\n",
    "    \"locked\",\n",
    "    \"restricted\",\n",
    "    \"closed\",\n",
    "    \"cancelled\",\n",
    "    \"deactivated\",\n",
    "    \"compromised\",\n",
    "    \"unauthorized activity\",\n",
    "    \"security breach\",\n",
    "    \"risk\",\n",
    "    \"violation\",\n",
    "\n",
    "    \"verify your account\",\n",
    "    \"confirm your identity\",\n",
    "    \"update your information\",\n",
    "    \"reset your password\",\n",
    "    \"click\",\n",
    "    \"open the attachment\",\n",
    "    \"respond immediately\",\n",
    "    \"take action\",\n",
    "    \"sign in to avoid\",\n",
    "\n",
    "    \"security team\",\n",
    "    \"support team\",\n",
    "    \"it department\",\n",
    "    \"administrator\",\n",
    "    \"compliance\",\n",
    "    \"customer service\",\n",
    "    \"official notice\",\n",
    "    \"automated message\",\n",
    "\n",
    "    \"important\",\n",
    "    \"attention\",\n",
    "    \"warning\",\n",
    "    \"alert\",\n",
    "    \"critical\",\n",
    "    \"serious\",\n",
    "    \"unusual activity\",\n",
    "    \"suspicious login\",\n",
    "\n",
    "    \"your account has been\",\n",
    "    \"action required\",\n",
    "    \"failure to comply\",\n",
    "    \"if you do not\",\n",
    "    \"to avoid suspension\",\n",
    "    \"we noticed unusual\",\n",
    "    \"for your security\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keywords(df, body_col=\"body\", keywords=None):\n",
    "\n",
    "    if body_col not in df.columns:      #verifica che la colonna vi sia (successivamente il corpo non si chiamerÃ  piÃ¹ body)\n",
    "        print(f\" Colonna '{body_col}' non trovata nel DataFrame\")\n",
    "        return 0\n",
    "\n",
    "    #regex\n",
    "    escaped_keywords = [re.escape(k) for k in keywords]\n",
    "    pattern = \"|\".join(escaped_keywords)\n",
    "\n",
    "    #ricerca delle entry che presentano almeno una parola chiave fra quelle indicate\n",
    "    mask = (\n",
    "        df[body_col]\n",
    "        .astype(str)\n",
    "        .str.contains(pattern, case=False, na=False, regex=True)\n",
    "    )\n",
    "\n",
    "    count = mask.sum()      #il numero di righe che presentano le parole chiave indicate\n",
    "\n",
    "    print(f\"Istanze con almeno una keyword nel {body_col}: {count}\")\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteggio dei link presenti nelle mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def conta_url(df, colonna=\"urls\"):\n",
    "\n",
    "    counts = Counter(df[colonna])\n",
    "    print(\"Conteggio righe per numero di URL:\")\n",
    "    for k in sorted(counts):\n",
    "        print(f\"{k} URL : {counts[k]} righe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisi Euristiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analizza_dataset(df0)\n",
    "analizza_dataset(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conta_url(df0)\n",
    "conta_url(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conta_file(df0))\n",
    "print(conta_file(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pattern(df0)\n",
    "count_pattern(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unione delle informazioni aggiuntive nel body\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compatta_detection(metadata_list, body):\n",
    "    \n",
    "    #Preleva le informazioni nella lista metadata_list nel seguente ordine\n",
    "    #FIELDS = ['sender', 'receiver', 'date', 'subject']\n",
    "    #e le formatta in questa forma:\n",
    "    #sender: xxxx | receiver: yyyy | date: wwww | subject: kkkk | body: zzzz\n",
    "    \n",
    "    metadata_prompt = (\n",
    "        \"sender: \" + str(metadata_list[0]) + \" | \" +\n",
    "        \"receiver: \" + str(metadata_list[1]) + \" | \" +\n",
    "        \"date: \" + str(metadata_list[2]) + \" | \" +\n",
    "        \"subject: \" + str(metadata_list[3])\n",
    "    )\n",
    "\n",
    "    body_text = metadata_prompt + \" | body: \" + body\n",
    "\n",
    "    return body_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_1 = pd.DataFrame()\n",
    "\n",
    "for idx, row in df1.iterrows():\n",
    "\n",
    "    #definizione della lista con le informazioni aggiuntive\n",
    "    metadata_list = [\n",
    "        row[\"sender\"],\n",
    "        row[\"receiver\"],\n",
    "        row[\"date\"],\n",
    "        row[\"subject\"]\n",
    "    ]\n",
    "    if pd.isna(row[\"subject\"]):\n",
    "        metadata_list[3]=\"\"             #Se il subject Ã¨ NaN si fornisce un carattere vuoto.                                 \n",
    "\n",
    "    body = row[\"body\"]\n",
    "\n",
    "    if pd.isna(body):\n",
    "        body=\"\"                         #body: NaN -> Body: \"\"\n",
    "\n",
    "    prompt = compatta_detection(metadata_list, body)\n",
    "\n",
    "    #Scrittura nel Dataframe di destinazione nel formato di Detection\n",
    "    df_output_1.at[idx, \"instruction\"] = \"You are a classification model specializing in emails, and your job is to detect phishing: respond only with \\\"0\\\" if it is not phishing or \\\"1\\\" if it is phishing, without explanations, symbols, additional letters, or other characters.\"\n",
    "    df_output_1.at[idx, \"text\"] = prompt\n",
    "    df_output_1.at[idx, \"label\"] = row[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_output_1)        #Verifica che df_output_1 sia equivalente alla dimensione di df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)                # len(df_output_1) -> 25812  | len(df1) -> 25812 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detection_label_1 = df_output_1.reset_index(drop=True)\n",
    "\n",
    "df_detection_label_1.to_json(\"df_to_check_1.json\", orient=\"records\", indent=2)      #Scrittura in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_detection_label_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulizia dei testi ripetuti\n",
    "\n",
    "Analizzando il dataset, molte mail risultano essere ripetuti nel corpo. Presentano le stesse frasi ripetute piÃ¹ volte senza un reale motivo, tramite questo codice successivo siamo in grado di filtrarle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Dimensioni usate per definire gli N-Gram\n",
    "NGRAM_SIZES = [7, 10, 15, 20]\n",
    "\n",
    "#ECompressione di tanti spazi consecutivi in un unico\n",
    "def clean_text(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "#Il corpo si trova successivamente a \"body:\", quindi viene estratto a partire dal compo text.\n",
    "def extract_body(input_field):\n",
    "    match = re.search(r'body:\\s*(.*)', input_field, re.IGNORECASE | re.DOTALL)\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "#Costruzione a partire da un testo di diversi N-Gram\n",
    "def build_ngrams(text, n):\n",
    "    words = text.split(' ')\n",
    "    return [\n",
    "        ' '.join(words[i:i+n])\n",
    "        for i in range(0, len(words), n)\n",
    "        if len(words[i:i+n]) == n\n",
    "    ]\n",
    "\n",
    "#Funzione per trovare la migliore coppia\n",
    "def best_pair_for_ngrams(ngrams):\n",
    "    if len(ngrams) < 2:\n",
    "        return None, None, -1.0\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(ngrams)\n",
    "\n",
    "    best_sim = -1.0\n",
    "    best_i, best_j = None, None\n",
    "\n",
    "    #Itera fra le diverse coppie e salva la migliore coppia e migliore similitudine\n",
    "    for i in range(len(ngrams)):\n",
    "        for j in range(i + 1, len(ngrams)):\n",
    "\n",
    "            sim = cosine_similarity(tfidf[i], tfidf[j])[0][0]\n",
    "\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_i, best_j = i, j\n",
    "\n",
    "    return ngrams[best_i], ngrams[best_j], best_sim     #ritorno della coppia migliore e \n",
    "                                                        #della migliore similitudine\n",
    "\n",
    "\n",
    "# ======================= MAIN =======================\n",
    "\n",
    "json_path = \"df_to_check_1.json\"    #json di input\n",
    "output_path = \"df_1_checked.json\"   #percorso di uscita\n",
    "threshold = 0.6                     #se la similaritÃ  fra n-gram nel testo Ã¨ maggiore di 0.6, il testo viene scartato\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "filtered_data = []         # <-- JSON finale senza duplicati\n",
    "removed_count = 0\n",
    "seen_count = 0\n",
    "\n",
    "for idx, instance in enumerate(data, 1):\n",
    "    seen_count += 1\n",
    "\n",
    "    raw_input = instance.get(\"text\", \"\")        \n",
    "    \n",
    "    body_text = extract_body(raw_input)     #estrae il corpo dal testo\n",
    "\n",
    "    if not body_text:\n",
    "        filtered_data.append(instance)      \n",
    "        continue\n",
    "\n",
    "    cleaned = clean_text(body_text)         #Pulizia testo da spazi in eccesso\n",
    "\n",
    "    global_best_sim = -1.0\n",
    "    global_best_pair = (None, None)\n",
    "    global_best_n = None\n",
    "\n",
    "    for n in NGRAM_SIZES:\n",
    "        ngrams = build_ngrams(cleaned, n)\n",
    "        ng1, ng2, sim = best_pair_for_ngrams(ngrams)\n",
    "        if sim > global_best_sim:           #si verifica che la similitudine migliore\n",
    "            global_best_sim = sim           #ottenuta Ã¨ migliore di quella globale per\n",
    "            global_best_pair = (ng1, ng2)   #il testo valutato\n",
    "            global_best_n = n\n",
    "\n",
    "    # === DECISIONE DI RIMOZIONE ===\n",
    "    if global_best_sim > threshold:\n",
    "        removed_count += 1\n",
    "        removed = True\n",
    "    else:\n",
    "        removed = False\n",
    "        filtered_data.append(instance)  # <-- ISTANZA TENUTA\n",
    "\n",
    "    # Preview prime 5\n",
    "    if idx <= 5:\n",
    "        print(f\"\\n=== ISTANZA {idx} PREVIEW ===\")\n",
    "        print(f\"Dimensione n-grammi: {global_best_n}\")\n",
    "        print(\"\\nN-gramma 1:\")\n",
    "        print(global_best_pair[0])\n",
    "        print(\"\\nN-gramma 2:\")\n",
    "        print(global_best_pair[1])\n",
    "        print(f\"\\nSimilaritÃ  (coseno TF-IDF): {global_best_sim:.4f}\")\n",
    "\n",
    "    # Stampa metriche (prime 5 + ogni 500)\n",
    "    if idx <= 5 or seen_count % 500 == 0:\n",
    "        print(\n",
    "            f\"[{seen_count}] removed={removed} | \"\n",
    "            f\"best_sim={global_best_sim:.4f} | \"\n",
    "            f\"removed_total={removed_count}/{seen_count}\"\n",
    "        )\n",
    "\n",
    "# ===== SALVATAGGIO JSON FILTRATO =====\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n=== RISULTATO FINALE ===\")\n",
    "print(f\"Istanze originali: {len(data)}\")\n",
    "print(f\"Istanze rimosse: {removed_count}\")\n",
    "print(f\"Istanze finali: {len(filtered_data)}\")\n",
    "print(f\"Percentuale rimossa: {(removed_count / seen_count) * 100:.2f}%\")\n",
    "print(f\"JSON filtrato salvato in: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento dei risultati in df1_pulito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open(\"df_1_checked.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)             \n",
    "    df1_pulito = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1_pulito)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df1_pulito)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF0_formattato   Ã¨ il dataset df0 con l'aggiunte nel testo delle informazioni aggiuntive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET_FINALE = DF con LABEL =0 + DF con LABEL = 1 pulito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Funzione ripetuta####\n",
    "def compatta_detection(metadata_list, body):\n",
    "    \n",
    "    #Preleva le informazioni nella lista metadata_list nel seguente ordine\n",
    "    #FIELDS = ['sender', 'receiver', 'date', 'subject']\n",
    "    #e le formatta in questa forma:\n",
    "    #sender: xxxx | receiver: yyyy | date: wwww | subject: kkkk | body: zzzz\n",
    "    \n",
    "    metadata_prompt = (\n",
    "        \"sender: \" + str(metadata_list[0]) + \" | \" +\n",
    "        \"receiver: \" + str(metadata_list[1]) + \" | \" +\n",
    "        \"date: \" + str(metadata_list[2]) + \" | \" +\n",
    "        \"subject: \" + str(metadata_list[3])\n",
    "    )\n",
    "\n",
    "    body_text = metadata_prompt + \" | body: \" + body\n",
    "\n",
    "    return body_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formattazione di df0 in df0_formattato\n",
    "\n",
    "df0_formattato = pd.DataFrame()\n",
    "\n",
    "for idx, row in df0.iterrows():\n",
    "    if idx % 3000 == 0:\n",
    "        print(f\"Processati {idx} record...\")\n",
    "\n",
    "    metadata_list = [\n",
    "        row[\"sender\"],\n",
    "        row[\"receiver\"],\n",
    "        row[\"date\"],\n",
    "        row[\"subject\"]\n",
    "    ]\n",
    "    if pd.isna(row[\"subject\"]):\n",
    "        metadata_list[3]=\"\"\n",
    "\n",
    "    body = row[\"body\"]\n",
    "\n",
    "    if pd.isna(body):\n",
    "        body=\"\"\n",
    "\n",
    "    prompt = compatta_detection(metadata_list, body)\n",
    "\n",
    "        # assegno i valori al DataFrame\n",
    "    df0_formattato.at[idx, \"instruction\"] = \"You are a classification model specializing in emails, and your job is to detect phishing: respond only with \\\"0\\\" if it is not phishing or \\\"1\\\" if it is phishing, without explanations, symbols, additional letters, or other characters.\"\n",
    "    df0_formattato.at[idx, \"text\"] = prompt\n",
    "    df0_formattato.at[idx, \"label\"] = row[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df0)\n",
    "dataset_metrics(df0_formattato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pur di avere un Dataset fianle bilanciato, sono state mantenute solo le prime 16812 righe\n",
    "#di df1_pulito. Grazie alle stampe precedenti notiamo che esistono 16812 istanze\n",
    "#con label 0, quindi ne aggiungiamo altrettante con label 1\n",
    "\n",
    "df1_pulito=df1_pulito.sample(frac=1).reset_index(drop=True)\n",
    "prima_parte = df1_pulito.iloc[:16812].copy()\n",
    "seconda_parte = df1_pulito.iloc[16812:].copy()\n",
    "df_finale = pd.concat([df0_formattato, prima_parte], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df0_formattato.iloc[3][\"text\"]\n",
    "#prima_parte.iloc[3][\"text\"]\n",
    "#df0_formattato.iloc[3][\"text\"]\n",
    "df_finale.iloc[3][\"text\"]           #stampa per vedere la corretta formattazione di df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisi Dataset\n",
    "\n",
    "dataset_metrics(df_finale)\n",
    "\n",
    "dataset_metrics(df0)\n",
    "dataset_metrics(prima_parte)\n",
    "dataset_metrics(seconda_parte)\n",
    "dataset_metrics(df1_pulito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_finale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creazione Dataset Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istogramma(df_detection,15,col_name=\"text\")   #Con l'istogramma si possono notare degli outlier\n",
    "                                              #con lunghezza eccessiva, questi vengono filtrati\n",
    "                                              #tramite questo codice.\n",
    "\n",
    "                                              #La tokenizzazione di prima ha fatto in modo da \n",
    "                                              #contare dei testi con token eccessivi, ma nel\n",
    "                                              #testo erano ancora presenti dei testi con molti\n",
    "                                              #spazi che incrementavano il numero di caratteri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_finale))       #33624\n",
    "\n",
    "df_finale = elimina_lunghe(df_finale, 4169, colonna=\"text\")\n",
    "\n",
    "print(len(df_finale))       #33619"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvataggio del dataset di detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finale.to_json(\"dataset_detection_totale.json\", orient=\"records\", force_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparazione Dataset di Generazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimozione \"Original Message\" dal corpo email, infatti le mail generate non dovrebbero rispondere a nessuna mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_by_pattern(df, pattern=\"Original Message\", text_col=\"text\"):\n",
    "\n",
    "\n",
    "    if text_col not in df.columns:\n",
    "        print(f\"âš ï¸ Colonna '{text_col}' non trovata nel DataFrame\")\n",
    "        return df\n",
    "\n",
    "    initial_rows = len(df)\n",
    "\n",
    "    #Trova le entry con \"Original Message nel corpo\"\n",
    "    mask = df[text_col].astype(str).str.contains(\n",
    "        pattern,\n",
    "        case=False,\n",
    "        na=False\n",
    "    )       \n",
    "\n",
    "    df_clean = df[~mask].reset_index(drop=True)     #eliminzione\n",
    "    removed = initial_rows - len(df_clean)\n",
    "\n",
    "    print(f\"Righe rimosse: {removed} (pattern: '{pattern}')\")\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_finale)\n",
    "count_pattern(df_finale)\n",
    "df_senza_original_message = remove_rows_by_pattern(df_finale)\n",
    "print(len(df_finale))\n",
    "print(len(df_senza_original_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_senza_original_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le mail che vogliamo generare sono le mail con label 1 in quanto vogliamo generare solo mail di phishing\n",
    "df_generazione =df_senza_original_message[df_senza_original_message[\"label\"]==1].reset_index(drop=True)\n",
    "dataset_metrics(df_generazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generazione.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nelle mail di generazione non dobbiamo generare anche informazioni come \"sender\"\n",
    "#\"receiver\" \"date\" \n",
    "df_output = df_generazione.copy()\n",
    "df_output[\"text\"] = df_output[\"text\"].str.extract(\n",
    "    r\"\\|\\s*(subject:\\s*.*)\",\n",
    "    flags=re.DOTALL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la generazione avviene tramite un formato diverso\n",
    "\n",
    "\"instruction\":\n",
    "\n",
    "\"input\":\n",
    "\n",
    "\"output\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_output.rename(columns={\n",
    "    \"text\": \"input\",\n",
    "    \"label\": \"output\"\n",
    "}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = df_output.iloc[:15000]  #accorcio la dimensione in quanto 15000 campioni sono\n",
    "                                    #sufficienti per il nostro task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_output,label_col=\"output\")\n",
    "print(df_output.loc[1, \"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creazione Dataset\n",
    "df_output.to_json(\"df_generation_totale.json\", orient=\"records\", indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.read_json(\"df_generation_totale.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split del Dataset in 3 parti\n",
    "\n",
    "Per la fase di generazione Ã¨ necessario generare un esempio di prompt a partire dalle mail di riferimento. Per questo motivo Ã¨ stata usata una rete LLM, LLama3.1 70b, per generare i prompt a partire dal corpo del messaggio.\n",
    "\n",
    "I dati cosÃ¬ ottenuti:\n",
    "\n",
    "* Prompt generato\n",
    "\n",
    "* Email associata\n",
    "\n",
    "Sono dati in ingresso a una rete di generazione di mail, per la fase di finetuning.\n",
    "\n",
    "A causa delle risorse limitate della piattaforma Ã¨ stato deciso per uno split in 3, in modo da generare i prompt singolarmente sui 3 dataset splittati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5000\n",
    "\n",
    "for i in range(3):\n",
    "    start = i * chunk_size\n",
    "    end = start + chunk_size\n",
    "    \n",
    "    df_chunk = df_output.iloc[start:end]\n",
    "    \n",
    "    filename = f\"dataset_generation_parziale_{i+1}.json\"\n",
    "    df_chunk.to_json(\n",
    "        filename,\n",
    "        orient=\"records\",\n",
    "        force_ascii=False,\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "    print(f\"Creato {filename} con {len(df_chunk)} righe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json(\"dataset_generation_parziale_1.json\")\n",
    "df2 = pd.read_json(\"dataset_generation_parziale_2.json\")\n",
    "df3 = pd.read_json(\"dataset_generation_parziale_3.json\")\n",
    "\n",
    "dataset_metrics(df1)\n",
    "dataset_metrics(df2)\n",
    "dataset_metrics(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo Euristiche del Dataset di Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detection = pd.read_json(\"dataset_detection_totale.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_generation = pd.read_json(\"df_generation_totale.json\")\n",
    "print(df_generation.columns.tolist())\n",
    "df_generation = df_generation.rename(columns={\n",
    "    'istruction': 'instruction',\n",
    "}).reset_index(drop=True)\n",
    "print(df_generation.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo Euristiche del Dataset di Training della fase di Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detection = pd.read_json(\"train_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_detection)\n",
    "\n",
    "analizza_dataset(df_detection,col_name=\"text\")\n",
    "print(\"Numero di file: \",conta_file(df_detection,col_name=\"text\"))\n",
    "count_pattern(df_detection,body_col=\"text\")\n",
    "count_keywords(df_detection,body_col=\"text\",keywords=phishing_urgency_keywords)\n",
    "istogramma(df_detection,15,col_name=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo Euristiche del Dataset di Testing della fase di Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detection = pd.read_json(\"test_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_detection)\n",
    "\n",
    "analizza_dataset(df_detection,col_name=\"text\")\n",
    "print(\"Numero di file: \",conta_file(df_detection,col_name=\"text\"))\n",
    "count_pattern(df_detection,body_col=\"text\")\n",
    "count_keywords(df_detection,body_col=\"text\",keywords=phishing_urgency_keywords)\n",
    "istogramma(df_detection,15,col_name=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controllo Euristiche del Dataset di Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generation = pd.read_json(\"df_generation_totale.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics(df_generation,label_col=\"output\")\n",
    "\n",
    "analizza_dataset(df_generation,col_name=\"input\")\n",
    "print(\"Numero di file: \",conta_file(df_generation,col_name=\"input\"))\n",
    "count_pattern(df_generation,body_col=\"input\")\n",
    "count_keywords(df_generation,body_col=\"input\",keywords=phishing_urgency_keywords)\n",
    "istogramma(df_generation,15,col_name=\"input\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
